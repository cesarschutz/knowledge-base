---
id: mba-prompt-engineering-para-devs
title: ü§ñ Prompt Engineering Para Devs
slug: /mba-prompt-engineering-para-devs
---

## üöÄ Prompt Engineering para Desenvolvedores

links:  
https://arxiv.org/abs/2005.14165  
https://microsoft.github.io/prompt-engineering/  
https://arxiv.org/abs/2201.11903  
https://arxiv.org/abs/2307.15337  
https://arxiv.org/abs/2305.10601  
https://arxiv.org/abs/2203.11171  
https://arxiv.org/abs/2210.11416  
https://arxiv.org/abs/2210.03629  



## üìù O que √© Prompt Engineering

A engenharia de prompts √© o processo em que voc√™ orienta as solu√ß√µes de **intelig√™ncia artificial generativa (IA generativa)** para gerar os resultados desejados.

Embora a IA generativa tente imitar os humanos, ela requer instru√ß√µes detalhadas para criar resultados relevantes e de alta qualidade.

Na engenharia de prompt, voc√™ escolhe os formatos, frases, palavras e s√≠mbolos mais adequados para orientar a IA a interagir com seus usu√°rios de forma mais significativa.

## üéØ Import√¢ncia para Desenvolvedores

- **Desenvolver e manter**
- **Explorar possibilidades**
- **Automatizar tarefas repetitivas**
- **Obter solu√ß√µes r√°pidas**
- **Auxiliar em processos complexos de desenvolvimento**
- **Aprimorar a colabora√ß√£o**

## ‚öôÔ∏è Utiliza√ß√£o e possibilidades

- **Documenta√ß√£o e Design Docs**
- **Implementa√ß√£o**
- **Code Review**
- **Mastermind e brainstorming**

---

## üìÑ Documenta√ß√£o e Design Docs

- **Requisitos e Produto** // TRD, PRD, FRD, User Stories
- **Design e Arquitetura** // System Design (HL), Low-Level Design (LLD), C4
- **Decis√µes T√©cnicas** // ADRs, RFCs
- **Engineering Guidelines** // Coding Standards, Code Review, Testing, CI/CD, Security
- **Ops e Infra** // Runbook, Playbook, Infrastructure Design Document, Post-morten

---

## üíª Implementa√ß√£o

- **Explora√ß√£o**
- **Contextualiza√ß√£o**
- **Tarefas e Plano de A√ß√£o**
- **Workflow e Rules**
- **Testing**
- **Debugging**
- **Refactoring**
- **An√°lise de Performance**
- **Commit & Pull Requests**

---

## üîç Code Review

- **An√°lise de Discrep√¢ncias** // Implementa√ß√£o reflete a documenta√ß√£o
- **Verifica√ß√µes de implementa√ß√£o de features**
- **Testabilidade e cobertura de c√≥digo**
- **Verifica√ß√£o de bugs**
- **Documenta√ß√£o / Coment√°rios Internos**
- **Coding Standards**

---

## üé® Tipos de Prompts e Varia√ß√µes

Existem diversas categorias e t√©cnicas de prompts que podem ser utilizadas por desenvolvedores para otimizar suas intera√ß√µes com IAs. Cada tipo oferece vantagens espec√≠ficas dependendo do contexto e caso de uso, desde tarefas simples sem exemplos pr√©vios at√© racioc√≠nios complexos e estruturados que melhoram significativamente a qualidade e precis√£o das respostas.

### üìã Exemplos

- **Zero-Shot**
- **One-Shot / Few-Shot**
- **Chain of Thought (CoT)**
- **Skeleton of Thought (SoT)**
- **Tree of Thought (ToT)**
- **Self-Consistency**
- **Directional Stimulus**
- **ReActing**

---

## Zero-Shot

Zero-Shot Prompting √© uma t√©cnica onde o modelo de linguagem recebe apenas a descri√ß√£o da tarefa, **sem nenhum exemplo** anterior. O objetivo √© avaliar a capacidade do modelo de generalizar e resolver o problema com base apenas na instru√ß√£o textual.

### Estudo

Essa abordagem ganhou destaque com o paper **"Language Models are Few-Shot Learners"** de Brown et al. (2020), publicado pela OpenAI. Nesse estudo, os pesquisadores demonstraram que modelos como o GPT-3 conseguem realizar tarefas complexas apenas com uma boa descri√ß√£o da tarefa no prompt, mesmo sem exemplos anteriores.

### Quando utilizar

- A tarefa √© simples e bem conhecida pelo modelo (por exemplo, perguntas factuais).
- N√£o h√° tempo ou espa√ßo para adicionar exemplos.
- Deseja-se testar a capacidade base do modelo de interpretar a tarefa.
- √â preciso processar uma grande quantidade de tarefas distintas e breves com o menor custo de tokens.

#### Link do paper: https://arxiv.org/abs/2005.14165

---

## Zero-Shot

### Vantagens

- Baixo custo de prepara√ß√£o do prompt.
- Alta escalabilidade.
- R√°pido para experimenta√ß√£o

### Limita√ß√µes

- Pode falhar em tarefas mais complexas ou menos frequentes para o modelo.
- N√£o oferece controle sobre o formato da resposta.
- Dependente da compreens√£o impl√≠cita do modelo sobre a tarefa.
- Alucina√ß√£o de respostas: o modelo pode gerar conte√∫do incorreto com alta confian√ßa.
- Varia√ß√£o com pequenas mudan√ßas na formata√ß√£o: prompts semanticamente equivalentes podem gerar resultados diferentes.
- Dificuldade em tarefas de racioc√≠nio l√≥gico, an√°lises comparativas ou infer√™ncia fora do contexto factual.

### Estrat√©gias de Mitiga√ß√£o

Mesmo mantendo a proposta de n√£o fornecer exemplos, algumas pr√°ticas ajudam a melhorar os resultados com Zero-Shot Prompting:

#### Especificidade:
Instru√ß√µes claras, que detalham o que se espera, aumentam a precis√£o.
- **Exemplo ruim:** "Analise esse c√≥digo"
- **Melhorado:** "Explique o que esse c√≥digo Go faz e liste poss√≠veis problemas de performance."

#### Linguagem declarativa e orientada √† Tarefa:
Prefer√™ncia por comandos diretos a perguntas abertas.
- **Exemplo:** "Liste os principais motivos para erros de mem√≥ria em da linguagem Go."

#### Sinaliza√ß√£o do formato esperado:
Solicita√ß√£o expl√≠cita de listas, t√≥picos, par√°grafos curtos etc.
- **Exemplo:** "Responda em forma de t√≥picos." ou "Escreva uma explica√ß√£o de 3 par√°grafos."

---

## Zero-Shot

### In-Context Instruction Learning

Mesmo sem exemplos, prompts estruturados com clareza (persona, formato, objetivo) ajudam o modelo a responder melhor. Instru√ß√µes mais detalhadas melhoram a performance zero-shot.

- **Antes:** "Explique o que √© uma goroutine"
- **Depois:** "Voc√™ √© um especialista em Go. Escreva dois par√°grafos explicando o que √© uma goroutine, como ela √© usada e quais s√£o suas limita√ß√µes. Seja claro, t√©cnico e direto."

### Boas pr√°ticas da Microsoft

- Especificar o papel do modelo ("Voc√™ √© um especialista em...")
- Especificar a sa√≠da desejada ("Responda em t√≥picos" ou "Formato JSON")
- Garantir que o modelo compreenda a meta ("Seu objetivo √©...")

**Exemplo:** "Voc√™ √© um consultor t√©cnico. Seu trabalho √© analisar este trecho de c√≥digo e sugerir melhorias de performance. Responda em t√≥picos e justifique cada sugest√£o."

#### Importante:
Apesar desse exemplo fornecer instru√ß√µes estruturadas, **n√£o apresenta nenhum exemplo anterior**. O modelo precisa inferir a tarefa com base apenas na instru√ß√£o natural.

https://microsoft.github.io/prompt-engineering/

---

## One-Shot / Few-Shot

Few-Shot Prompting √© uma t√©cnica onde fornecemos **um pequeno n√∫mero de exemplos (normalmente entre 1 e 5)** para que o modelo entenda o padr√£o de entrada e sa√≠da antes de gerar uma nova resposta. O modelo "aprende" apenas com base nesses exemplos, dentro do pr√≥prio prompt, sem qualquer re-treinamento.

### Estudo

A t√©cnica foi formalizada no artigo seminal **"Language Models are Few-Shot Learners"** de Brown et al. (2020), que apresentou o GPT-3 e sua capacidade de realizar tarefas complexas com apenas alguns exemplos embutidos na entrada textual.

### Quando utilizar

- A tarefa tem **m√∫ltiplas formas de execu√ß√£o v√°lidas**, e voc√™ deseja orientar o estilo da resposta.
- O modelo **comete erros ou se comporta de forma inconsistente** em Zero-Shot.
- A tarefa √© **relativamente complexa ou espec√≠fica**, e pode se beneficiar de demonstra√ß√µes diretas.
- √â necess√°rio **replicar padr√µes lingu√≠sticos, t√©cnicos ou formais** espec√≠ficos.

---

## One-Shot / Few-Shot

### Vantagens

- **Precis√£o aumentada:** exemplos ajudam o modelo a compreender nuances da tarefa.
- **Consist√™ncia de estilo:** √∫til para gerar c√≥digo/documenta√ß√£o com padroniza√ß√£o.
- **Pouco custo de engenharia:** mais simples do que treinar modelos.

### Limita√ß√µes

- **Custo em tokens:** exemplos ocupam espa√ßo no prompt, reduzindo espa√ßo para contexto.
- **Depend√™ncia da qualidade dos exemplos:** exemplos amb√≠guos ou mal formulados comprometem a resposta.
- **Fragilidade √† ordem:** mudar a ordem dos exemplos pode afetar o desempenho.

### Estrutura e exemplos

```
Exemplo 1:
Entrada: <texto de entrada>
Sa√≠da: <resposta esperada>

Exemplo 2:
Entrada: <texto de entrada>
Sa√≠da: <resposta esperada>
```

**Prompt:**
"Gere testes unit√°rios para fun√ß√µes em Go"

**Exemplo:**
```
Fun√ß√£o:
func Soma(a, b int) int { return a + b }

Teste:
func TestSoma(t *testing.T) { r := Soma(2, 3) if r != 5 { t.Errorf("esperado 5, obteve %d", r) } }

Fun√ß√£o:
func Multiplica(a, b int) int { return a * b }

Teste:
```

**Resultado esperado:**
O modelo gera o teste para Multiplica seguindo o estilo e estrutura do exemplo anterior, com nomes de fun√ß√µes, vari√°veis e mensagens consistentes.

### Comparativo

| Tipo de Prompt | Exemplos | Precis√£o | Controle de Sa√≠da | Custo |
|----------------|----------|----------|-------------------|--------|
| Zero-Shot | Nenhum | M√©dia | Baixo | Baixo |
| One-Shot | 1 | M√©dia+ | M√©dio | M√©dio |
| Few-Shot | 2-5 | Alta | Alto | Alto |

---

## Chain of Thought (CoT)

Chain of Thought (CoT) √© uma t√©cnica de engenharia de prompt que instrui o modelo a externalizar seu racioc√≠nio **passo a passo**, permitindo que ele resolva tarefas que exigem l√≥gica, m√∫ltiplas etapas ou opera√ß√µes intermedi√°rias. Em vez de apenas dar a resposta final, o modelo mostra seu processo de pensamento.

### Estudo

A t√©cnica foi formalizada no paper **"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"** de Wei et al. (2022), demonstrando que grandes modelos como PaLM e GPT-3 apresentam desempenho significativamente superior em tarefas de racioc√≠nio l√≥gico e aritm√©tico quando induzidos a pensar de forma encadeada.

### Advanced Reasoning

- O CoT √© a **funda√ß√£o para os recursos de Advanced Reasoning em LLMs**, como GPT-4, Claude e Gemini. Esses modelos foram treinados com instru√ß√µes e exemplos que incentivam racioc√≠nio multietapas, explica√ß√µes l√≥gicas e reflex√µes audit√°veis.
- Chain of Thought permite que o modelo n√£o apenas **chegue √† resposta**, mas tamb√©m **demonstre como chegou at√© ela**, oferecendo transpar√™ncia, confiabilidade e contexto t√©cnico.

### Quando utilizar

- Diagn√≥stico de falhas e bugs
- Planejamento l√≥gico de processos
- Argumenta√ß√µes comparativas entre abordagens

#### Link do paper: https://arxiv.org/abs/2201.11903

---

## Chain of Thought (CoT)

### Vantagens

- **Racioc√≠nio expl√≠cito:** permite que o modelo demonstre seu processo de pensamento passo a passo.
- **Maior resolu√ß√£o de problemas complexos:** melhora significativamente o desempenho em tarefas que exigem m√∫ltiplas etapas de racioc√≠nio.
- **Transpar√™ncia e auditabilidade:** torna o processo decis√≥rio do modelo vis√≠vel, facilitando a verifica√ß√£o da l√≥gica utilizada.

### Limita√ß√µes

- Gera sa√≠das mais longas, o que pode ser custoso em prompts com limite de tokens.
- Pode introduzir ru√≠do se o modelo gerar cadeias de pensamento incorretas.
- Requer modelo suficientemente treinado para compreender e aplicar o passo a passo com qualidade.
- Se n√£o combinado com crit√©rios de parada, pode prolongar desnecessariamente o racioc√≠nio.
  - "Pense passo a passo at√© chegar a uma conclus√£o √∫nica e final."
  - "Pare quando tiver certeza da resposta."
  - "Ap√≥s concluir as etapas, retorne apenas a resposta final."

### Estrutura e exemplos

```
Voc√™ √© um engenheiro de software com 20 anos de experi√™ncia em sistemas concorrentes e distribu√≠dos. Seu trabalho √© revisar o c√≥digo a seguir e identificar falhas ou melhorias. Pense passo a passo, justificando cada ponto com base nas pr√°ticas recomendadas em Go. Ao final, revise a sequ√™ncia de etapas e forne√ßa uma conclus√£o objetiva.

Use a seguinte estrutura:
Etapa 1: <descri√ß√£o>
Etapa 2: <descri√ß√£o> ...
Resultado final: <conclus√£o>
```

---

## Chain of Thought (CoT)

#### 1. Debugging com racioc√≠nio l√≥gico

**Prompt:**

```
Voc√™ √© um desenvolvedor Go. Analise o seguinte c√≥digo e explique, passo a passo, por que ele pode causar um erro:

var lista []string
fmt.Println(lista[0])
```

**Resposta esperada:**

Etapa 1: A vari√°vel lista √© declarada como slice de strings, mas n√£o foi inicializada.

Etapa 2: Um slice n√£o inicializado tem tamanho zero (len(lista) == 0).

Etapa 3: Acessar lista[0] viola o limite do slice, pois n√£o h√° elementos.

Resultado final: o programa entra em p√¢nico (panic) por acesso fora dos limites.

---

## Chain of Thought (CoT)

#### 2. Refatora√ß√£o com justificativas t√©cnicas

**Prompt:**

```
Reescreva a fun√ß√£o abaixo seguindo o padr√£o early return e explique cada modifica√ß√£o passo a passo:

func Validar(u Usuario) error {
    var err error
    if u.Email == "" {
        err = errors.New("email obrigat√≥rio")
    } else {
        if u.Senha == "" {
            err = errors.New("senha obrigat√≥ria")
        } else {
            err = nil
        }
    }
    return err
}
```

---

## Chain of Thought (CoT)

#### 3. Planejamento b√°sico

**Prompt:**

```
Descreva todas as etapas envolvidas na migra√ß√£o de uma aplica√ß√£o monol√≠tica para microservi√ßos baseados em eventos. Para cada etapa, inclua pr√©-requisitos, riscos e valida√ß√µes. Organize o racioc√≠nio em sequ√™ncia l√≥gica e valide antes de concluir.
```

**Resposta esperada:**

Etapa 1: Identifica√ß√£o dos dom√≠nios de neg√≥cio.

Etapa 2: Defini√ß√£o de fronteiras de contexto (bounded contexts).

Etapa 3: Extra√ß√£o de servi√ßos mais isolados com menor acoplamento.

Etapa 4: Implementa√ß√£o de mensageria (ex: RabbitMQ) com fallback e DLQs.

Etapa 5: Implementa√ß√£o de observabilidade: logs, m√©tricas e tracing.

Etapa 6: Testes de regress√£o antes de redirecionar tr√°fego.

Resultado final: Arquitetura distribu√≠da validada com ganhos de resili√™ncia e escalabilidade.

---

## Chain of Thought (CoT)

### Estrat√©gias inspiradas na Anthropic Prompt Library

- **Persona + Objetivo + Estrutura clara:** contextualiza a fun√ß√£o do modelo e define o tom da resposta.
- **Chamado √† reflex√£o l√≥gica:** "Pense passo a passo", "Justifique cada etapa".
- **Formato de sa√≠da padronizado:** etapas numeradas + conclus√£o objetiva.
- **Autoavalia√ß√£o embutida:** "Verifique se todos os passos est√£o consistentes".
- **Crit√©rio de parada l√≥gico:** encerrar ao atingir o racioc√≠nio final.

### T√©cnicas avan√ßadas de CoT com delimita√ß√µes estruturais (Anthropic-style)

Modelos como Claude e GPT respondem melhor quando o prompt apresenta **delimita√ß√µes estruturais expl√≠citas**. Uma t√©cnica bastante utilizada pela Anthropic, segundo sua pr√≥pria Claude Prompt Library, √© o uso de **delimitadores XML-like** como `<thought>`, `<reasoning>`, `<answer>`, etc., para **separar racioc√≠nio da resposta final**, melhorar a legibilidade, e tornar o prompt mais audit√°vel.

### Varia√ß√µes comuns de marcadores

- `<context>` ‚Äî delimita contexto inicial ou sistema.
- `<thought>` ou `<reasoning>` ‚Äî cont√©m o racioc√≠nio l√≥gico.
- `<step>` ‚Äî pode ser usado para dividir em etapas internas.
- `<answer>` ‚Äî resposta direta, sem explica√ß√µes.
- `<final_decision>` ‚Äî quando h√° m√∫ltiplas alternativas sendo avaliadas.

### Motiva√ß√£o para usar marcadores estruturais

- Reduz ambiguidade entre racioc√≠nio e resposta.
- Permite que o modelo organize suas ideias de maneira hier√°rquica.
- Facilita an√°lises posteriores do output por humanos ou outros sistemas.
- Ajuda o modelo a se manter dentro de um fluxo l√≥gico, sem saltos.

---

## Chain of Thought (CoT)

### Exemplo

**Prompt:**

```
Voc√™ √© um engenheiro de software especialista em arquitetura de sistemas web. Sua tarefa √© pensar passo a passo sobre os requisitos t√©cnicos para construir um backend de uma aplica√ß√£o de Todo List colaborativa com autentica√ß√£o de usu√°rios, categorias personaliz√°veis e suporte a tarefas compartilhadas entre times.

Escreva seu racioc√≠nio entre <thought> e o resumo t√©cnico final entre <answer>. Use tamb√©m <step> para dividir o pensamento por √°rea de responsabilidade.
```

**Resposta esperada:**

```xml
<thought>
  <step>
    <title>1. Autentica√ß√£o e gerenciamento de usu√°rios</title>
    A aplica√ß√£o deve suportar login via e-mail e senha com autentica√ß√£o baseada em tokens JWT. Usu√°rios precisam ser persistidos em um banco relacional com campos como email, senha hash, nome e data de cria√ß√£o.
  </step>
  <step>
    <title>2. Modelagem de tarefas</title>
    Cada tarefa deve conter t√≠tulo, descri√ß√£o, status (pendente, conclu√≠da), data de vencimento, categoria e ID do criador. As tarefas devem poder ser atribu√≠das a m√∫ltiplos usu√°rios.
  </step>
  <step>
    <title>3. Compartilhamento e permiss√µes</title>
    O sistema precisa de um controle de permiss√µes onde usu√°rios podem ser organizados em times, com permiss√µes como leitura, escrita e administra√ß√£o de tarefas dentro de projetos ou categorias.
  </step>
  <step>
    <title>4. Armazenamento e tecnologia</title>
    Uma stack adequada seria: backend em Go com Echo ou Fiber, banco PostgreSQL, autentica√ß√£o com JWT e middleware para RBAC (role-based access control).
  </step>
</thought>

<answer>
O backend da aplica√ß√£o Todo List deve ser constru√≠do em Go, com suporte a JWT para autentica√ß√£o, PostgreSQL para persist√™ncia e estrutura multiusu√°rio com times e permiss√µes de acesso. As tarefas s√£o entidades colaborativas atribu√≠das a m√∫ltiplos usu√°rios com categorias personalizadas e status gerenci√°vel.
</answer>
```

---

## Chain of Thought (CoT)

### Comparativo

| Tipo de Prompt | Requer Exemplos | Gera Racioc√≠nio | Ideal para |
|----------------|-----------------|-----------------|------------|
| Zero-Shot | Nenhum | M√©dia | Baixo |
| One-Shot / Few-Shot | Sim | Opcional | Imitar formato, estilo ou padr√µes |
| Chain of Thought | Indiferente | Sim | L√≥gica, planejamento, an√°lise, debugging |

---

## Skeleton of Thought (SoT)

Skeleton of Thought Prompting √© uma varia√ß√£o de Chain of Thought onde o modelo √© instru√≠do a seguir uma **estrutura l√≥gica pr√©-definida (um esqueleto)**, com marcadores claros de se√ß√µes ou ideias centrais que devem ser preenchidas com racioc√≠nio. Essa t√©cnica √© ideal quando o desenvolvedor deseja que a IA produza respostas **organizadas**, **completas** e **sem fugir da estrutura** desejada.

### Estudo

A t√©cnica foi inspirada diretamente em um estudo acad√™mico publicado por Zhang et al. (2023) no paper **"Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding"**. Nesse trabalho, os autores mostraram que √© poss√≠vel separar a gera√ß√£o do **esqueleto estrutural da resposta** da gera√ß√£o do **conte√∫do detalhado de cada parte**, promovendo paralelismo e coer√™ncia. Embora o foco t√©cnico do paper seja a melhoria de desempenho por decodifica√ß√£o paralela, o mesmo princ√≠pio √© aplic√°vel a prompting estrutural em diversos contextos como documenta√ß√µes, arquitetura de software, etc.

### Quando utilizar

- Resumos t√©cnicos com se√ß√µes fixas
- Documenta√ß√µes, ADRs, Templates
- Quando h√° necessidade de controlar a sa√≠da e formato de uma resposta

#### Link do paper: https://arxiv.org/abs/2307.15337
---

## Skeleton of Thought (SoT)

### Exemplo

**Prompt:**

```
Voc√™ √© um engenheiro de software especializado em performance e escalabilidade. Sua tarefa √© propor uma solu√ß√£o para implementar um rate limiter robusto que limite a taxa de requisi√ß√µes por cliente. Estruture sua resposta com os seguintes t√≥picos:

- Contexto do problema
- Requisitos funcionais e n√£o funcionais
- Estrat√©gia de rate limiting
- Stack tecnol√≥gica sugerida
- Considera√ß√µes de concorr√™ncia e escalabilidade
- Conclus√£o t√©cnica
```

**Resposta esperada:**

**Contexto do problema:** A API ser√° utilizada por centenas de clientes simultaneamente e precisa garantir que nenhum cliente ultrapasse o limite de 1000 requisi√ß√µes por minuto. O sistema deve suportar at√© 100 mil requisi√ß√µes por segundo em picos e evitar sobrecarga no backend. √â necess√°rio garantir que o rate limiter funcione em ambiente distribu√≠do.

**Requisitos funcionais e n√£o funcionais:**
- Cada cliente deve ter limites de requisi√ß√£o individuais.
- Os limites devem ser reiniciados por janela deslizante (sliding window).
- O sistema deve ser resiliente, com baixa lat√™ncia (&lt;5ms).
- Suporte a m√∫ltiplas inst√¢ncias e execu√ß√£o concorrente.

**Estrat√©gia de rate limiting:** A t√©cnica ideal √© o uso de Token Bucket com sliding window e sincroniza√ß√£o via Redis. Cada cliente ter√° um bucket virtual com capacidade e taxa de preenchimento ajust√°vel. A cada requisi√ß√£o, ser√° feita uma tentativa de consumir um token. Se o token n√£o estiver dispon√≠vel, a requisi√ß√£o ser√° rejeitada com HTTP 429.

**Stack tecnol√≥gica sugerida:**
- Linguagem: Go
- Middleware HTTP: Echo ou Fiber
- Rate limiting core: implementa√ß√£o pr√≥pria ou uso do pacote golang.org/x/time/rate
- Armazenamento distribu√≠do: Redis Cluster para controle de tokens sincronizado entre inst√¢ncias
- Monitoramento: Prometheus + Grafana

**Considera√ß√µes de concorr√™ncia e escalabilidade:**
- Redis deve usar LUA scripts at√¥micos para evitar race conditions.
- Shard de clientes por chave (hash) pode distribuir melhor a carga.
- Uso de buffers internos no processo local para opera√ß√µes de leitura r√°pidas em cache.
- Evitar chamadas de rede por requisi√ß√£o usando prefetching de tokens.

**Conclus√£o t√©cnica:** O uso de Token Bucket com Redis distribu√≠do e implementa√ß√£o otimizada em Go atende aos requisitos de lat√™ncia e escalabilidade. A estrutura modular permite reuso em outros servi√ßos. √â necess√°rio fazer testes de carga com Locust e simula√ß√£o de falhas para validar a robustez da solu√ß√£o em produ√ß√£o.

---

## Skeleton of Thought (SoT)

### Quando usar SoT vs CoT "puro"

| Quando... | Use Skeleton of Thought |
|-----------|------------------------|
| Voc√™ quer controle total do formato | Sim |
| A resposta deve ser dividida por t√≥picos | Sim |
| A tarefa exige checklist estruturado | Sim |
| A IA costuma se perder na estrutura | Sim |
| A l√≥gica for altamente explorat√≥ria | N√£o |

### Comparativo

| T√©cnica | Requer estrutura? | Raciocina passo a passo? | Ideal para... |
|---------|------------------|-------------------------|---------------|
| Zero-Shot | N√£o | N√£o | Consultas diretas, respostas factuais |
| One-Shot / Few-Shot | Parcial | Opcional | Repetir padr√µes de exemplo com precis√£o |
| Chain of Thought | N√£o | Sim | Diagn√≥stico, debugging, racioc√≠nio t√©cnico |
| Skeleton of Thought | Sim | Opcional | Respostas organizadas, documenta√ß√µes, especifica√ß√µes |

---

## Tree of Thought (ToT)

Tree of Thought (ToT) √© uma extens√£o da t√©cnica Chain of Thought (CoT) que permite que o modelo explore **m√∫ltiplos caminhos de racioc√≠nio paralelos ou alternativos** antes de tomar uma decis√£o final. Em vez de um racioc√≠nio linear, o ToT incentiva o modelo a **ramificar ideias** e **avaliar alternativas**, como se estivesse construindo uma √°rvore de decis√µes.

### Estudo

A t√©cnica foi formalizada por Yao et al., 2023, no paper **Tree of Thoughts: Deliberate Problem Solving with Large Language Models**, mostrando ganhos significativos em tarefas complexas como jogos de l√≥gica, planejamento e racioc√≠nio anal√≠tico estruturado.

### Quando utilizar

- A tarefa √© amb√≠gua ou tem **m√∫ltiplas solu√ß√µes poss√≠veis**.
- √â necess√°rio **comparar estrat√©gias ou caminhos distintos**.
- A decis√£o final depende de **m√∫ltiplos crit√©rios ou trade-offs**.
- Deseja-se simular **racioc√≠nio humano deliberado** com pondera√ß√µes.

#### Link do paper: https://arxiv.org/abs/2305.10601

---

## Tree of Thought (ToT)

### Exemplo

**Prompt:**

```
Voc√™ √© um engenheiro de software especialista em sistemas distribu√≠dos. Um cliente quer limitar o acesso √† sua API que recebe at√© 100 mil requisi√ß√µes por segundo. Gere m√∫ltiplas abordagens (caminhos de racioc√≠nio) para resolver esse problema. Para cada abordagem, exponha os pr√≥s e contras. Ao final, selecione a mais adequada com base em escalabilidade, confiabilidade e lat√™ncia.
```

**Resposta esperada:**

**Caminho 1: Token Bucket com Redis**
- Permite bursts controlados.
- F√°cil de implementar.
- Redis pode ser um gargalo sob carga intensa.
- Exige replica√ß√£o e scripts at√¥micos.

**Caminho 2: Leaky Bucket com cache local**
- Boa regulariza√ß√£o de tr√°fego.
- Alta previsibilidade de lat√™ncia.
- Menos flex√≠vel para bursts.
- Cache local pode divergir entre inst√¢ncias.

**Caminho 3: Algoritmo Sliding Window Log**
- Precis√£o de tempo real por requisi√ß√£o.
- Alta granularidade.
- Alto consumo de mem√≥ria e custo computacional.
- Dif√≠cil de escalar sem otimiza√ß√µes.

### Avalia√ß√£o dos caminhos
- **Escalabilidade:** Caminhos 1 e 2 s√£o melhores.
- **Baixa lat√™ncia:** Caminho 2 se destaca.
- **Facilidade de manuten√ß√£o:** Caminho 1 √© mais consolidado.

**Escolha final:**
Token Bucket com Redis + buffer local representa o melhor equil√≠brio entre simplicidade, performance e toler√¢ncia a falhas.

---

## Tree of Thought (ToT)

### T√©cnicas auxiliares

**Expans√£o controlada de caminhos:** limite a profundidade e n√∫mero de alternativas para evitar dispers√£o.

```
"Apresente no m√°ximo 3 caminhos distintos para resolver este problema e desenvolva at√© 2 n√≠veis de subetapas para cada um."
```

**Crit√©rios de decis√£o expl√≠citos:** guie o modelo com par√¢metros como "menor custo", "maior confiabilidade", etc.

```
"Para cada abordagem proposta, avalie com base em custo, lat√™ncia e escalabilidade. Escolha a melhor com base nesses crit√©rios."
```

**Reavalia√ß√£o iterativa:** o modelo pode revisar suas escolhas se uma nova ramifica√ß√£o se mostrar superior.

```
"Depois de explorar todas as op√ß√µes, reavalie as decis√µes com base nos resultados observados em cada caminho e corrija se necess√°rio."
```

---

## Tree of Thought (ToT)

### Combina√ß√£o com outras t√©cnicas: ToT + CoT + SoT

Tree of Thought √© altamente compat√≠vel com outras estrat√©gias de prompting, resultando em maior controle, completude e explicabilidade. Abaixo est√° um exemplo que combina Tree of Thought com Chain of Thought e Skeleton of Thought.

**Prompt combinado (ToT + CoT + SoT):**

```
Voc√™ √© um engenheiro de software especialista em sistemas distribu√≠dos. Sua tarefa √© projetar uma solu√ß√£o de rate limiting para uma API que suporta 100 mil requisi√ß√µes por segundo. Apresente 3 estrat√©gias distintas, usando o seguinte esqueleto para cada uma:

- Vis√£o geral da abordagem
- Etapas detalhadas do racioc√≠nio (pense passo a passo, como um engenheiro resolveria isso em produ√ß√£o)
- Principais vantagens
- Principais desvantagens
- Quando usar essa abordagem

Ao final, decida qual abordagem representa o melhor equil√≠brio para o caso proposto.
```

**Resposta esperada (resumo):**

**Estrat√©gia 1: Token Bucket com Redis distribu√≠do**
- **Vis√£o geral:** Permite pequenos bursts, boa toler√¢ncia √† falha.
- **Etapas:** Descrever uso de token bucket, scripts LUA at√¥micos, cache local.
- **Vantagens:** Popular, flex√≠vel, boa documenta√ß√£o.
- **Desvantagens:** Requer Redis de alta disponibilidade.
- **Uso ideal:** Quando se deseja flexibilidade e controle individualizado.

**Estrat√©gia 2: Leaky Bucket com armazenamento local**
- **Vis√£o geral:** Regulariza fluxo de forma constante.
- **Etapas:** Descrever deque local, fallback em caso de falha.
- **Vantagens:** Mais simples, previs√≠vel.
- **Desvantagens:** Cache local pode gerar inconsist√™ncia.
- **Uso ideal:** Quando a estabilidade do fluxo √© mais importante que burst handling.

**Estrat√©gia 3: Sliding Window Log com shard por API key**
- **Vis√£o geral:** Rastreia cada requisi√ß√£o.
- **Etapas:** Uso de logs temporais por cliente.
- **Vantagens:** Alta precis√£o temporal.
- **Desvantagens:** Alto custo de mem√≥ria.
- **Uso ideal:** Quando a justi√ßa de tempo real √© indispens√°vel.

**Decis√£o final:** A estrat√©gia 1 oferece o melhor equil√≠brio entre performance, controle e robustez para a maioria dos cen√°rios em produ√ß√£o com cargas elevadas.

---

## Tree of Thought (ToT)

### Comparativo com outras t√©cnicas

| T√©cnica | Requer estrutura? | Raciocina passo a passo? | Gera m√∫ltiplas alternativas? | Ideal para... |
|---------|------------------|-------------------------|------------------------------|---------------|
| Zero-Shot | N√£o | N√£o | N√£o | Consultas diretas, respostas factuais |
| Few-Shot | Parcial | Opcional | N√£o | Repetir padr√µes de exemplo com precis√£o |
| Chain of Thought | N√£o | Sim | N√£o | Diagn√≥stico, debugging, racioc√≠nio t√©cnico |
| Skeleton of Thought | Sim | Opcional | N√£o | Respostas organizadas, documenta√ß√µes, especifica√ß√µes |
| Tree of Thought | Parcial | Sim | Sim | Decis√£o entre estrat√©gias, brainstorming estruturado |

---

## üìä Resumo comparativo: CoT, SoT, ToT

| T√©cnica | Situa√ß√£o ideal | Justificativa | Exemplo de prompt |
|---------|----------------|---------------|-------------------|
| Chain of Thought (CoT) | Explicar bugs | Racioc√≠nio encadeado com l√≥gica explicada | "Explique passo a passo por que o c√≥digo abaixo pode gerar um panic em Go. Analise como um engenheiro faria debug em produ√ß√£o." |
| Skeleton of Thought (SoT) | Especificar m√≥dulos com se√ß√µes fixas | Exige consist√™ncia e organiza√ß√£o por t√≥picos | "Crie uma especifica√ß√£o t√©cnica para um m√≥dulo de autentica√ß√£o JWT usando os seguintes t√≥picos: requisitos funcionais, modelo de dados, fluxos, valida√ß√µes, seguran√ßa e integra√ß√£o." |
| Tree of Thought (ToT) | Comparar op√ß√µes (ex: cache) | Explora√ß√£o de alternativas e decis√£o justificada | "Considere tr√™s formas de aplicar cache em um sistema web: in-memory, Redis e CDN. Para cada uma, descreva a estrat√©gia, vantagens, desvantagens e cen√°rio ideal de uso. Ao final, selecione a melhor com base em lat√™ncia, custo e simplicidade." |
| SoT + CoT | Planejamento de arquitetura | Organiza√ß√£o por t√≥picos com racioc√≠nio detalhado | "Estruture a arquitetura de um sistema de Todo List com autentica√ß√£o, API REST e persist√™ncia. Responda por t√≥picos: vis√£o geral, autentica√ß√£o, banco de dados, fluxos principais, escalabilidade. Em cada t√≥pico, pense passo a passo como um arquiteto de software." |
| ToT + SoT + CoT | Definir melhor stack tecnol√≥gica | Estrutura, m√∫ltiplas alternativas e racioc√≠nio interno | "Compare as stacks Go, Node.js e Python para microservi√ßos. Para cada uma, siga os t√≥picos: performance, ecossistema, produtividade, complexidade de deploy e casos de uso recomendados. Dentro de cada t√≥pico, pense passo a passo. Ao final, recomende a stack ideal para um sistema com 10 microsservi√ßos interconectados." |
| ToT + SoT | Compara√ß√£o de bancos de dados | An√°lise comparativa organizada por crit√©rios | "Compare os tipos de banco de dados SQL, NoSQL e NewSQL para uma aplica√ß√£o de leitura intensiva. Para cada um, responda usando os t√≥picos: modelo de dados, escalabilidade, lat√™ncia, consist√™ncia e custo operacional. Ao final, indique qual abordagem √© mais indicada para esse cen√°rio." |

---

## üìà Resumo comparativo: CoT, SoT, ToT

### Casos de uso abordados

| T√©cnica aplicada | Situa√ß√£o | Justificativa |
|-----------------|----------|---------------|
| Chain of Thought (CoT) | Explicar por que um bug ocorre | Precisa de racioc√≠nio encadeado com l√≥gica explicada |
| Skeleton of Thought (SoT) | Especificar um m√≥dulo de autentica√ß√£o com se√ß√µes fixas | Exige consist√™ncia e organiza√ß√£o por t√≥picos |
| Tree of Thought (ToT) | Comparar 3 formas de aplicar cache (in-memory, Redis, CDN) | Exige explora√ß√£o de alternativas e decis√£o final justificada |
| SoT + CoT | Planejar arquitetura de um sistema com API, banco e autentica√ß√£o | Exige estrutura e racioc√≠nio t√©cnico dentro de cada se√ß√£o |
| ToT + SoT + CoT | Definir melhor stack entre Go, Node.js e Python para microservi√ßos | Requer estrutura, m√∫ltiplas alternativas e racioc√≠nio interno completo |
| ToT + SoT | Comparar bancos SQL, NoSQL e NewSQL para leitura intensiva | M√∫ltiplas estrat√©gias com an√°lise t√©cnica estruturada, sem exigir CoT |

### Conclus√£o

Cada t√©cnica possui for√ßas complementares:

- **CoT** ‚Üí Racioc√≠nio l√≥gico.
- **SoT** ‚Üí Organiza√ß√£o e completude.
- **ToT** ‚Üí Compara√ß√£o e tomada de decis√£o.

---

## Self-Consistency

### Como funciona a t√©cnica

1. O prompt induz o modelo a pensar passo a passo (Chain of Thought).
2. A tarefa √© executada **diversas vezes** (tipicamente de 5 a 10).
3. As respostas geradas s√£o ent√£o **coletadas e comparadas**.
4. A sa√≠da final √© definida por **vota√ß√£o majorit√°ria** ou por **m√©trica de consist√™ncia**.

O princ√≠pio √© simples: o modelo pode cometer erros em uma cadeia espec√≠fica, mas, com m√∫ltiplas execu√ß√µes, as respostas **mais confi√°veis tendem a convergir**.

### Quando utilizar

- H√° ambiguidade matem√°tica ou estrutural.
- A tarefa √© suscet√≠vel a varia√ß√µes de racioc√≠nio.
- O modelo tende a dar boas respostas √†s vezes, mas n√£o sempre.
- Voc√™ precisa aumentar a confiabilidade da sa√≠da com pouco custo computacional adicional.

### Por que funciona

LLMs operam com amostragem probabil√≠stica (ex: temperatura > 0), o que os torna suscet√≠veis a gerar varia√ß√µes, desvios ou respostas inconsistentes. Ao gerar m√∫ltiplas execu√ß√µes:

- Reduzimos alucina√ß√µes isoladas.
- Aumentamos a chance de obter uma resposta estatisticamente s√≥lida.
- Priorizamos coer√™ncia entre caminhos l√≥gicos distintos.

#### Link do paper: https://arxiv.org/abs/2203.11171

---

## Self-Consistency

### Situa√ß√£o

Voc√™ est√° desenvolvendo a estimativa de custo mensal para uma aplica√ß√£o em produ√ß√£o na AWS. A aplica√ß√£o utiliza:

- 10 inst√¢ncias EC2 t3.large (regi√£o US East)
- 1 TB de armazenamento EBS
- 1 Load Balancer
- 100 GB de transfer√™ncia de dados saindo por m√™s

Como pequenos desvios podem ocorrer entre execu√ß√µes, voc√™ decide aplicar Self-Consistency para gerar m√∫ltiplas estimativas e selecionar a mais confi√°vel.

**Prompt (com CoT):**

```
"Calcule o custo total mensal dessa infraestrutura. Pense passo a passo."
```

### Execu√ß√µes (resumidas):

**Execu√ß√£o 1**
- EC2: 10 x $0.0832 x 730h = $607.36
- EBS: 1024 GB x $0.10 = $102.40
- ELB: $18.00
- Data transfer: 100 GB x $0.09 = $9.00
- **Total: $736.76**

**Execu√ß√£o 2**
- EC2: $605.00 (aproximado)
- EBS: $100.00
- ELB: $18
- Transfer√™ncia: $9
- **Total: $732.00**

**Execu√ß√£o 3**
- EC2: 10 √ó 0.0832 √ó 730 = $607.36
- EBS: 1TB √ó 0.10 = $102.40
- Load Balancer: $18
- Data Out: $9
- **Total: $736.76**

### Resultado da Self-Consistency:

A estimativa de **$736.76** foi repetida em duas execu√ß√µes com c√°lculos detalhados e consistentes. Ela √© considerada a resposta mais confi√°vel por frequ√™ncia e exatid√£o.

**Resposta selecionada:** $736.76 ‚Äî confirmada como mais precisa e recorrente entre as m√∫ltiplas cadeias de racioc√≠nio.

---

## Self-Consistency

### Aplica√ß√µes pr√°ticas em engenharia de software

- Estimativas de custo e capacidade (cloud, infra, storage)
- Planejamento de sizing de ambientes
- Valida√ß√£o de resultados num√©ricos ou previs√µes algor√≠tmicas
- Verifica√ß√£o de hip√≥teses t√©cnicas sob m√∫ltiplos crit√©rios
- Compara√ß√µes de l√≥gica interna em testes de arquitetura

### Dicas de aplica√ß√£o

- Gere 5 a 10 respostas com **temperatura > 0.5** para estimular caminhos diversos.
- Normalize o formato da sa√≠da antes de comparar.
- Pode ser usada manualmente (humano escolhe) ou automaticamente (via vota√ß√£o).

### Exemplo completo usando todas as dicas de aplica√ß√£o

Voc√™ quer estimar o n√∫mero ideal de shards para uma base de dados multitenant com 80.000 clientes.

**Prompt:**

"Qual o n√∫mero ideal de shards para particionar uma base de dados com 80.000 clientes, considerando escalabilidade, performance e isolamento? Pense passo a passo."

**Aplica√ß√£o pr√°tica das dicas:**

- **Temperatura variada (diversidade de racioc√≠nio):** Voc√™ gera 8 respostas com temperaturas variando entre 0.6 e 0.8 para explorar caminhos diferentes.
- **Normaliza√ß√£o da sa√≠da:** Antes de comparar, remove diferen√ßas como:
  - "~10 shards", "10", "dez" ‚Üí tudo √© convertido para "10"
  - Formata√ß√£o monet√°ria ou num√©rica (R$10k = 10000)
- **Sele√ß√£o da resposta final:**
  - 5 das 8 execu√ß√µes sugerem 10 shards, com racioc√≠nios como "8000 clientes por shard", "balanceamento operacional", "flexibilidade para crescimento futuro".
  - Voc√™ implementa um script simples que conta a frequ√™ncia e seleciona a mais recorrente.

**Resultado final:** 10 shards ‚Äî justificado por frequ√™ncia, coer√™ncia t√©cnica e compatibilidade com os crit√©rios operacionais do sistema.

---

## üéØ Directional Stimulus / Directed Prompting

Directed Prompting (ou Directional Stimulus Prompting) √© uma t√©cnica que guia a resposta do modelo ao utilizar verbetes, comandos ou est√≠mulos direcionais. Diferente de prompts abertos ou vagos, essa abordagem indica como o modelo deve pensar ou responder, influenciando estilo, formato, foco ou tipo de racioc√≠nio esperado.

### Quando utilizar

- Quando √© necess√°rio obter **respostas previs√≠veis ou formatadas**.
- Quando deseja-se guiar o racioc√≠nio por um **estilo de resposta desejado**.
- Quando a resposta precisa estar em um **formato parse√°vel** (como JSON, XML, YAML).
- Quando a tarefa exige foco expl√≠cito (ex: "responda como um arquiteto", "explique em t√≥picos").

### Benef√≠cios de Directed Prompting

- Reduz ambiguidade e alucina√ß√£o.
- Padroniza a forma da resposta.
- Melhora a utilidade program√°tica da sa√≠da (ex: para scripts ou interfaces).
- Permite controle educado do comportamento do modelo, sem necessidade de complexidade adicional.

#### Link do paper: https://arxiv.org/abs/2210.11416

---

## Directional Stimulus

### Exemplos de comandos direcionais comuns

- "Liste..."
- "Compare..."
- "Explique com exemplos..."
- "Responda em formato JSON"
- "Justifique cada item"
- "Explique como um arquiteto s√™nior faria"
- "Divida em t√≥picos: contexto, estrat√©gia, riscos e conclus√£o"

Esses comandos **atuam como est√≠mulos condicionais**, que alteram tanto **o formato quanto a profundidade** da resposta.

### Aplica√ß√µes em engenharia de software

- Gerar documenta√ß√£o t√©cnica com estrutura espec√≠fica
- Listar vantagens/desvantagens de solu√ß√µes de arquitetura
- Descrever fluxos de autentica√ß√£o, cache, filas, escalabilidade
- Padronizar output para consumo por sistemas (JSON, YAML)

---

## Directional Stimulus

### Exemplo: Compara√ß√£o de tecnologias com Directed Prompting / Direction Stimulus

**Prompt:**

```
Compare as tecnologias Kafka, RabbitMQ e Amazon SQS para uso em sistemas distribu√≠dos. Responda nos t√≥picos: caracter√≠sticas principais, throughput, confiabilidade, complexidade operacional e quando usar cada uma.
```

**Resposta esperada:**

**Kafka**
- **Caracter√≠sticas:** distribu√≠do, baseado em logs, alta durabilidade.
- **Throughput:** muito alto, ideal para big data e pipelines de evento.
- **Confiabilidade:** alt√≠ssima, com replica√ß√£o e reten√ß√£o configur√°vel.
- **Complexidade:** alta ‚Äî exige setup de brokers, Zookeeper (ou KRaft), monitora√ß√£o ativa.
- **Quando usar:** quando o volume de dados √© alto e a ordem das mensagens √© cr√≠tica.

**RabbitMQ**
- **Caracter√≠sticas:** orientado a fila, com suporte a m√∫ltiplos protocolos (AMQP, MQTT).
- **Throughput:** m√©dio-alto, mais r√°pido para mensagens pequenas.
- **Confiabilidade:** boa, com suporte a ACK, DLQ e persist√™ncia.
- **Complexidade:** moderada, bom tooling e f√°cil opera√ß√£o.
- **Quando usar:** para mensageria tradicional, RPC e integra√ß√£o entre servi√ßos.

**Amazon SQS**
- **Caracter√≠sticas:** gerenciado, escal√°vel automaticamente, simples de operar.
- **Throughput:** escal√°vel sob demanda.
- **Confiabilidade:** excelente, com redund√¢ncia e reentrega autom√°tica.
- **Complexidade:** baixa ‚Äî sem servidores para administrar.
- **Quando usar:** quando se busca simplicidade e escalabilidade sem overhead de opera√ß√£o.

---

## Directional Stimulus vs SoT

| Aspecto | Skeleton of Thought | Directed Prompting |
|---------|--------------------|--------------------|
| Tipo de controle | Estrutura r√≠gida com se√ß√µes definidas | Est√≠mulo leve baseado em instru√ß√µes textuais |
| Modelo deve seguir t√≥picos? | Sim | N√£o necessariamente |
| Liberdade de formata√ß√£o | Baixa | M√©dia |
| Uso t√≠pico | Documenta√ß√µes, especifica√ß√µes, planejamento | Compara√ß√µes, respostas formatadas, controle de estilo |
| Exemplo de prompt | SoT: "Preencha os t√≥picos: vis√£o geral, arquitetura, riscos, conclus√£o." | "Liste as vantagens e desvantagens da arquitetura em t√≥picos." |

---

## üîÑ ReAct (Reasoning + Action)

ReAct (Reasoning + Acting) √© uma t√©cnica de prompting que permite que LLMs combinem **racioc√≠nio passo a passo (Chain of Thought)** com a **execu√ß√£o de a√ß√µes externas** ‚Äî como chamadas a ferramentas, busca em bancos de dados, execu√ß√£o de c√≥digo ou uso de APIs.

### Estudo

Foi formalizada no paper **"ReAct: Synergizing Reasoning and Acting in Language Models"** por Yao et al., 2022. A ideia √© fazer com que o modelo pense de forma deliberada e execute a√ß√µes iterativas com base nesse racioc√≠nio.

### Quando utilizar

- Quando o modelo precisa consultar APIs, sistemas ou bancos de dados.
- Quando o racioc√≠nio sozinho **n√£o √© suficiente** para responder.
- Quando h√° depend√™ncia de **informa√ß√µes externas din√¢micas**.

### Vantagens e Limita√ß√µes do ReAct Prompting

**Vantagens:**
- Permite que o modelo **combine racioc√≠nio com a√ß√£o** em tempo real.
- Ideal para **constru√ß√£o de agentes interativos** (SRE, DevOps, suporte, CI/CD).
- Gera **respostas audit√°veis**, pois explicita cada passo (Thought ‚Üí Action ‚Üí Observation).
- Pode ser iterado com base em **feedbacks din√¢micos**, como logs ou APIs externas.
- Compat√≠vel com ferramentas e ambientes j√° operacionais (ex: Docker, scripts, observabilidade).

**Limita√ß√µes:**
- Exige que a a√ß√£o esteja simulada ou dispon√≠vel via ferramenta externa.
- Requer sistemas que integrem e interpretem a Action e Observation corretamente.
- A estrutura Thought/Action/Observation deve ser seguida √† risca, o que pode limitar a fluidez da linguagem.
- Aumenta a complexidade de constru√ß√£o e teste do prompt.

#### Link do paper: https://arxiv.org/abs/2210.03629

---

## ReAct

### Exemplo t√©cnico: Inspe√ß√£o de containers com ReAct e ferramenta Docker

**Prompt**

```
Voc√™ √© um engenheiro de plataforma. Utilize racioc√≠nio passo a passo e a ferramenta Docker (dispon√≠vel via MCP) para inspecionar os containers que est√£o rodando no sistema. Seu objetivo √© entender o estado atual da infraestrutura. Para cada etapa, siga o padr√£o:

Thought: ...
Action: ...
Observation: ...
Final Answer: ...
```

**Resposta esperada**

```
Thought: Para entender o estado atual da infraestrutura, o primeiro passo √© listar os containers que est√£o em execu√ß√£o.
Action: usar ferramenta Docker com comando "docker ps"
Observation: 12 containers ativos, incluindo nginx, postgres, redis, app-core, worker-1, worker-2, api-gateway, etc.

Thought: Precisamos identificar quais containers est√£o usando mais CPU.
Action: usar ferramenta Docker com comando "docker stats"
Observation: O container worker-2 est√° consumindo 78% de CPU, bem acima dos demais.

Thought: Isso pode indicar um ciclo de processamento cont√≠nuo. Verificar logs desse container.
Action: usar ferramenta Docker com comando "docker logs worker-2 --tail=50"
Observation: Logs mostram tarefa de processamento de mensagens em repeti√ß√£o com erro de parsing.

Final Answer: O container worker-2 est√° sobrecarregado processando mensagens com erro cont√≠nuo. Deve ser investigada a origem dos dados e aplicada corre√ß√£o no pipeline de parsing.
```

```
Thought: Se a aplica√ß√£o est√° inacess√≠vel, o container pode ter parado ou falhado. Vamos consultar o MCP para verificar o estado do container payments-api. Action: GET /mcp/containers?filter=name:payments-api Observation: Container payments-api est√° em status "Exited" com c√≥digo 137 (Out of Memory).

Thought: A falha indica que o container excedeu o uso de mem√≥ria. Verificar hist√≥rico de uso de recursos. Action: GET /mcp/metrics/payments-api?range=4h Observation: Pico de uso de mem√≥ria √†s 09:17, 09:32, 09:50 ‚Äî ultrapassando o limite de 512MiB.

Thought: A aplica√ß√£o precisa de mais mem√≥ria. Vamos ajustar o limite e reiniciar. Action: PATCH /mcp/containers/payments-api { "memory_limit": "1GiB" } Observation: Novo limite definido com sucesso.

Thought: Agora vamos reiniciar o container. Action: POST /mcp/containers/payments-api/restart Observation: Container iniciado com sucesso. Status atual: "Running".

Final Answer: O container payments-api falhou por falta de mem√≥ria. O limite foi ajustado para 1GiB e a aplica√ß√£o voltou ao ar com sucesso.
```

```
Thought: O erro 503 geralmente indica indisponibilidade do backend. Vamos verificar se h√° ocorr√™ncias no log do servi√ßo de checkout.
Action: GET /logs?service=checkout&since=2h
Observation: 503 errors found at 14:03, 14:05, 14:09. Spike correlates with deploy.

Thought: Pode estar relacionado ao √∫ltimo deploy. Verificar hist√≥rico de deploys.
Action: GET /deploys?service=checkout
Observation: √öltimo deploy √†s 14:00.

Thought: Erros iniciaram imediatamente ap√≥s o deploy. Validar rollback.
Action: POST /rollback?service=checkout
Observation: Rollback initiated. Traffic stabilizing.

Final Answer: O erro 503 foi causado por uma falha no √∫ltimo deploy √†s 14:00. Rollback aplicado com sucesso.
```

### Aplica√ß√µes pr√°ticas em engenharia de software

- **Depura√ß√£o com logs ou trace APIs**

---

## ReAct

### Diferen√ßa entre ReAct e CoT puro

| ReAct | Chain of Thought (CoT) |
|-------|------------------------|
| Interage com o ambiente externo | Raciocina apenas internamente |
| Usa ferramentas | N√£o executa a√ß√µes |
| Baseado em observa√ß√µes iterativas | Baseado em racioc√≠nio est√°tico |
| Ideal para agentes ou assistentes | Ideal para explica√ß√µes e l√≥gica |