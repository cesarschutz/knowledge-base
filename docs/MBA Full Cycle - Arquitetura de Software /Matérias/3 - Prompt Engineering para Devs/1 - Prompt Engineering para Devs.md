---
id: mba-prompt-engineering-para-devs
title: ğŸ¤– Prompt Engineering Para Devs
slug: /mba-prompt-engineering-para-devs
---

## ğŸš€ **Prompt Engineering para Desenvolvedores**

### ğŸ“š **ReferÃªncias AcadÃªmicas**
- https://arxiv.org/abs/2005.14165  
- https://microsoft.github.io/prompt-engineering/  
- https://arxiv.org/abs/2201.11903  
- https://arxiv.org/abs/2307.15337  
- https://arxiv.org/abs/2305.10601  
- https://arxiv.org/abs/2203.11171  
- https://arxiv.org/abs/2210.11416  
- https://arxiv.org/abs/2210.03629



## ğŸ“ **O que Ã© Prompt Engineering**

A engenharia de prompts Ã© o processo em que vocÃª orienta as soluÃ§Ãµes de **inteligÃªncia artificial generativa (IA generativa)** para gerar os resultados desejados.

Embora a IA generativa tente imitar os humanos, ela requer instruÃ§Ãµes detalhadas para criar resultados relevantes e de alta qualidade.

Na engenharia de prompt, vocÃª escolhe os formatos, frases, palavras e sÃ­mbolos mais adequados para orientar a IA a interagir com seus usuÃ¡rios de forma mais significativa.

## ğŸ¯ **ImportÃ¢ncia para Desenvolvedores**

- **Desenvolver e manter**
- **Explorar possibilidades**
- **Automatizar tarefas repetitivas**
- **Obter soluÃ§Ãµes rÃ¡pidas**
- **Auxiliar em processos complexos de desenvolvimento**
- **Aprimorar a colaboraÃ§Ã£o**

## âš™ï¸ **UtilizaÃ§Ã£o e Possibilidades**

- **DocumentaÃ§Ã£o e Design Docs**
- **ImplementaÃ§Ã£o**
- **Code Review**
- **Mastermind e brainstorming**

---

## ğŸ“„ **DocumentaÃ§Ã£o e Design Docs**

- **Requisitos e Produto** // TRD, PRD, FRD, User Stories
- **Design e Arquitetura** // System Design (HL), Low-Level Design (LLD), C4
- **DecisÃµes TÃ©cnicas** // ADRs, RFCs
- **Engineering Guidelines** // Coding Standards, Code Review, Testing, CI/CD, Security
- **Ops e Infra** // Runbook, Playbook, Infrastructure Design Document, Post-morten

---

## ğŸ’» **ImplementaÃ§Ã£o**

- **ExploraÃ§Ã£o**
- **ContextualizaÃ§Ã£o**
- **Tarefas e Plano de AÃ§Ã£o**
- **Workflow e Rules**
- **Testing**
- **Debugging**
- **Refactoring**
- **AnÃ¡lise de Performance**
- **Commit & Pull Requests**

---

## ğŸ” **Code Review**

- **AnÃ¡lise de DiscrepÃ¢ncias** // ImplementaÃ§Ã£o reflete a documentaÃ§Ã£o
- **VerificaÃ§Ãµes de implementaÃ§Ã£o de features**
- **Testabilidade e cobertura de cÃ³digo**
- **VerificaÃ§Ã£o de bugs**
- **DocumentaÃ§Ã£o / ComentÃ¡rios Internos**
- **Coding Standards**

---

## ğŸ¨ **Tipos de Prompts e VariaÃ§Ãµes**

Existem diversas categorias e tÃ©cnicas de prompts que podem ser utilizadas por desenvolvedores para otimizar suas interaÃ§Ãµes com IAs. Cada tipo oferece vantagens especÃ­ficas dependendo do contexto e caso de uso, desde tarefas simples sem exemplos prÃ©vios atÃ© raciocÃ­nios complexos e estruturados que melhoram significativamente a qualidade e precisÃ£o das respostas.

### ğŸ“‹ **TÃ©cnicas DisponÃ­veis**

- **Zero-Shot**
- **One-Shot / Few-Shot**
- **Chain of Thought (CoT)**
- **Skeleton of Thought (SoT)**
- **Tree of Thought (ToT)**
- **Self-Consistency**
- **Directional Stimulus**
- **ReAct (Reasoning + Action)**

---

## ğŸ¯ **Zero-Shot Prompting**

Zero-Shot Prompting Ã© uma tÃ©cnica onde o modelo de linguagem recebe apenas a descriÃ§Ã£o da tarefa, **sem nenhum exemplo** anterior. O objetivo Ã© avaliar a capacidade do modelo de generalizar e resolver o problema com base apenas na instruÃ§Ã£o textual.

### ğŸ“š **Estudo de Base**

Essa abordagem ganhou destaque com o paper **"Language Models are Few-Shot Learners"** de Brown et al. (2020), publicado pela OpenAI. Nesse estudo, os pesquisadores demonstraram que modelos como o GPT-3 conseguem realizar tarefas complexas apenas com uma boa descriÃ§Ã£o da tarefa no prompt, mesmo sem exemplos anteriores.

### â° **Quando Utilizar**

- A tarefa Ã© simples e bem conhecida pelo modelo (por exemplo, perguntas factuais).
- NÃ£o hÃ¡ tempo ou espaÃ§o para adicionar exemplos.
- Deseja-se testar a capacidade base do modelo de interpretar a tarefa.
- Ã‰ preciso processar uma grande quantidade de tarefas distintas e breves com o menor custo de tokens.

#### ğŸ”— **Link do Paper:** https://arxiv.org/abs/2005.14165

---

## ğŸ¯ **Zero-Shot Prompting**

### âœ… **Vantagens**

- Baixo custo de preparaÃ§Ã£o do prompt.
- Alta escalabilidade.
- RÃ¡pido para experimentaÃ§Ã£o

### âš ï¸ **LimitaÃ§Ãµes**

- Pode falhar em tarefas mais complexas ou menos frequentes para o modelo.
- NÃ£o oferece controle sobre o formato da resposta.
- Dependente da compreensÃ£o implÃ­cita do modelo sobre a tarefa.
- AlucinaÃ§Ã£o de respostas: o modelo pode gerar conteÃºdo incorreto com alta confianÃ§a.
- VariaÃ§Ã£o com pequenas mudanÃ§as na formataÃ§Ã£o: prompts semanticamente equivalentes podem gerar resultados diferentes.
- Dificuldade em tarefas de raciocÃ­nio lÃ³gico, anÃ¡lises comparativas ou inferÃªncia fora do contexto factual.

### ğŸ› ï¸ **EstratÃ©gias de MitigaÃ§Ã£o**

Mesmo mantendo a proposta de nÃ£o fornecer exemplos, algumas prÃ¡ticas ajudam a melhorar os resultados com Zero-Shot Prompting:

#### ğŸ¯ **Especificidade:**
InstruÃ§Ãµes claras, que detalham o que se espera, aumentam a precisÃ£o.
- **Exemplo ruim:** "Analise esse cÃ³digo"
- **Melhorado:** "Explique o que esse cÃ³digo Go faz e liste possÃ­veis problemas de performance."

#### ğŸ’¬ **Linguagem Declarativa e Orientada Ã  Tarefa:**
PreferÃªncia por comandos diretos a perguntas abertas.
- **Exemplo:** "Liste os principais motivos para erros de memÃ³ria em da linguagem Go."

#### ğŸ“‹ **SinalizaÃ§Ã£o do Formato Esperado:**
SolicitaÃ§Ã£o explÃ­cita de listas, tÃ³picos, parÃ¡grafos curtos etc.
- **Exemplo:** "Responda em forma de tÃ³picos." ou "Escreva uma explicaÃ§Ã£o de 3 parÃ¡grafos."

---

## ğŸ¯ **Zero-Shot Prompting**

### ğŸ§  **In-Context Instruction Learning**

Mesmo sem exemplos, prompts estruturados com clareza (persona, formato, objetivo) ajudam o modelo a responder melhor. InstruÃ§Ãµes mais detalhadas melhoram a performance zero-shot.

- **Antes:** "Explique o que Ã© uma goroutine"
- **Depois:** "VocÃª Ã© um especialista em Go. Escreva dois parÃ¡grafos explicando o que Ã© uma goroutine, como ela Ã© usada e quais sÃ£o suas limitaÃ§Ãµes. Seja claro, tÃ©cnico e direto."

### ğŸ¢ **Boas PrÃ¡ticas da Microsoft**

- Especificar o papel do modelo ("VocÃª Ã© um especialista em...")
- Especificar a saÃ­da desejada ("Responda em tÃ³picos" ou "Formato JSON")
- Garantir que o modelo compreenda a meta ("Seu objetivo Ã©...")

**Exemplo:** "VocÃª Ã© um consultor tÃ©cnico. Seu trabalho Ã© analisar este trecho de cÃ³digo e sugerir melhorias de performance. Responda em tÃ³picos e justifique cada sugestÃ£o."

#### âš ï¸ **Importante:**
Apesar desse exemplo fornecer instruÃ§Ãµes estruturadas, **nÃ£o apresenta nenhum exemplo anterior**. O modelo precisa inferir a tarefa com base apenas na instruÃ§Ã£o natural.

ğŸ”— **ReferÃªncia:** https://microsoft.github.io/prompt-engineering/

---

## ğŸ“ **One-Shot / Few-Shot Prompting**

Few-Shot Prompting Ã© uma tÃ©cnica onde fornecemos **um pequeno nÃºmero de exemplos (normalmente entre 1 e 5)** para que o modelo entenda o padrÃ£o de entrada e saÃ­da antes de gerar uma nova resposta. O modelo "aprende" apenas com base nesses exemplos, dentro do prÃ³prio prompt, sem qualquer re-treinamento.

### ğŸ“š **Estudo de Base**

A tÃ©cnica foi formalizada no artigo seminal **"Language Models are Few-Shot Learners"** de Brown et al. (2020), que apresentou o GPT-3 e sua capacidade de realizar tarefas complexas com apenas alguns exemplos embutidos na entrada textual.

### â° **Quando Utilizar**

- A tarefa tem **mÃºltiplas formas de execuÃ§Ã£o vÃ¡lidas**, e vocÃª deseja orientar o estilo da resposta.
- O modelo **comete erros ou se comporta de forma inconsistente** em Zero-Shot.
- A tarefa Ã© **relativamente complexa ou especÃ­fica**, e pode se beneficiar de demonstraÃ§Ãµes diretas.
- Ã‰ necessÃ¡rio **replicar padrÃµes linguÃ­sticos, tÃ©cnicos ou formais** especÃ­ficos.

---

## ğŸ“ **One-Shot / Few-Shot Prompting**

### âœ… **Vantagens**

- **PrecisÃ£o aumentada:** exemplos ajudam o modelo a compreender nuances da tarefa.
- **ConsistÃªncia de estilo:** Ãºtil para gerar cÃ³digo/documentaÃ§Ã£o com padronizaÃ§Ã£o.
- **Pouco custo de engenharia:** mais simples do que treinar modelos.

### âš ï¸ **LimitaÃ§Ãµes**

- **Custo em tokens:** exemplos ocupam espaÃ§o no prompt, reduzindo espaÃ§o para contexto.
- **DependÃªncia da qualidade dos exemplos:** exemplos ambÃ­guos ou mal formulados comprometem a resposta.
- **Fragilidade Ã  ordem:** mudar a ordem dos exemplos pode afetar o desempenho.

### ğŸ“‹ **Estrutura e Exemplos**

```
Exemplo 1:
Entrada: <texto de entrada>
SaÃ­da: <resposta esperada>

Exemplo 2:
Entrada: <texto de entrada>
SaÃ­da: <resposta esperada>
```

**Prompt:**
"Gere testes unitÃ¡rios para funÃ§Ãµes em Go"

**Exemplo:**
```
FunÃ§Ã£o:
func Soma(a, b int) int { return a + b }

Teste:
func TestSoma(t *testing.T) { r := Soma(2, 3) if r != 5 { t.Errorf("esperado 5, obteve %d", r) } }

FunÃ§Ã£o:
func Multiplica(a, b int) int { return a * b }

Teste:
```

**Resultado esperado:**
O modelo gera o teste para Multiplica seguindo o estilo e estrutura do exemplo anterior, com nomes de funÃ§Ãµes, variÃ¡veis e mensagens consistentes.

### ğŸ“Š **Comparativo**

| Tipo de Prompt | Exemplos | PrecisÃ£o | Controle de SaÃ­da | Custo |
|----------------|----------|----------|-------------------|--------|
| Zero-Shot | Nenhum | MÃ©dia | Baixo | Baixo |
| One-Shot | 1 | MÃ©dia+ | MÃ©dio | MÃ©dio |
| Few-Shot | 2-5 | Alta | Alto | Alto |

---

## ğŸ§  **Chain of Thought (CoT)**

Chain of Thought (CoT) Ã© uma tÃ©cnica de engenharia de prompt que instrui o modelo a externalizar seu raciocÃ­nio **passo a passo**, permitindo que ele resolva tarefas que exigem lÃ³gica, mÃºltiplas etapas ou operaÃ§Ãµes intermediÃ¡rias. Em vez de apenas dar a resposta final, o modelo mostra seu processo de pensamento.

### ğŸ“š **Estudo de Base**

A tÃ©cnica foi formalizada no paper **"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"** de Wei et al. (2022), demonstrando que grandes modelos como PaLM e GPT-3 apresentam desempenho significativamente superior em tarefas de raciocÃ­nio lÃ³gico e aritmÃ©tico quando induzidos a pensar de forma encadeada.

### ğŸš€ **Advanced Reasoning**

- O CoT Ã© a **fundaÃ§Ã£o para os recursos de Advanced Reasoning em LLMs**, como GPT-4, Claude e Gemini. Esses modelos foram treinados com instruÃ§Ãµes e exemplos que incentivam raciocÃ­nio multietapas, explicaÃ§Ãµes lÃ³gicas e reflexÃµes auditÃ¡veis.
- Chain of Thought permite que o modelo nÃ£o apenas **chegue Ã  resposta**, mas tambÃ©m **demonstre como chegou atÃ© ela**, oferecendo transparÃªncia, confiabilidade e contexto tÃ©cnico.

### â° **Quando Utilizar**

- DiagnÃ³stico de falhas e bugs
- Planejamento lÃ³gico de processos
- ArgumentaÃ§Ãµes comparativas entre abordagens

#### ğŸ”— **Link do Paper:** https://arxiv.org/abs/2201.11903

---

## ğŸ§  **Chain of Thought (CoT)**

### âœ… **Vantagens**

- **RaciocÃ­nio explÃ­cito:** permite que o modelo demonstre seu processo de pensamento passo a passo.
- **Maior resoluÃ§Ã£o de problemas complexos:** melhora significativamente o desempenho em tarefas que exigem mÃºltiplas etapas de raciocÃ­nio.
- **TransparÃªncia e auditabilidade:** torna o processo decisÃ³rio do modelo visÃ­vel, facilitando a verificaÃ§Ã£o da lÃ³gica utilizada.

### âš ï¸ **LimitaÃ§Ãµes**

- Gera saÃ­das mais longas, o que pode ser custoso em prompts com limite de tokens.
- Pode introduzir ruÃ­do se o modelo gerar cadeias de pensamento incorretas.
- Requer modelo suficientemente treinado para compreender e aplicar o passo a passo com qualidade.
- Se nÃ£o combinado com critÃ©rios de parada, pode prolongar desnecessariamente o raciocÃ­nio.
  - "Pense passo a passo atÃ© chegar a uma conclusÃ£o Ãºnica e final."
  - "Pare quando tiver certeza da resposta."
  - "ApÃ³s concluir as etapas, retorne apenas a resposta final."

### ğŸ“‹ **Estrutura e Exemplos**

```
VocÃª Ã© um engenheiro de software com 20 anos de experiÃªncia em sistemas concorrentes e distribuÃ­dos. Seu trabalho Ã© revisar o cÃ³digo a seguir e identificar falhas ou melhorias. Pense passo a passo, justificando cada ponto com base nas prÃ¡ticas recomendadas em Go. Ao final, revise a sequÃªncia de etapas e forneÃ§a uma conclusÃ£o objetiva.

Use a seguinte estrutura:
Etapa 1: <descriÃ§Ã£o>
Etapa 2: <descriÃ§Ã£o> ...
Resultado final: <conclusÃ£o>
```

---

## Chain of Thought (CoT)

#### ğŸ› **1. Debugging com RaciocÃ­nio LÃ³gico**

**Prompt:**

```
VocÃª Ã© um desenvolvedor Go. Analise o seguinte cÃ³digo e explique, passo a passo, por que ele pode causar um erro:

var lista []string
fmt.Println(lista[0])
```

**Resposta esperada:**

Etapa 1: A variÃ¡vel lista Ã© declarada como slice de strings, mas nÃ£o foi inicializada.

Etapa 2: Um slice nÃ£o inicializado tem tamanho zero (len(lista) == 0).

Etapa 3: Acessar lista[0] viola o limite do slice, pois nÃ£o hÃ¡ elementos.

Resultado final: o programa entra em pÃ¢nico (panic) por acesso fora dos limites.

---

## Chain of Thought (CoT)

#### ğŸ”§ **2. RefatoraÃ§Ã£o com Justificativas TÃ©cnicas**

**Prompt:**

```
Reescreva a funÃ§Ã£o abaixo seguindo o padrÃ£o early return e explique cada modificaÃ§Ã£o passo a passo:

func Validar(u Usuario) error {
    var err error
    if u.Email == "" {
        err = errors.New("email obrigatÃ³rio")
    } else {
        if u.Senha == "" {
            err = errors.New("senha obrigatÃ³ria")
        } else {
            err = nil
        }
    }
    return err
}
```

---

## Chain of Thought (CoT)

#### ğŸ“‹ **3. Planejamento BÃ¡sico**

**Prompt:**

```
Descreva todas as etapas envolvidas na migraÃ§Ã£o de uma aplicaÃ§Ã£o monolÃ­tica para microserviÃ§os baseados em eventos. Para cada etapa, inclua prÃ©-requisitos, riscos e validaÃ§Ãµes. Organize o raciocÃ­nio em sequÃªncia lÃ³gica e valide antes de concluir.
```

**Resposta esperada:**

Etapa 1: IdentificaÃ§Ã£o dos domÃ­nios de negÃ³cio.

Etapa 2: DefiniÃ§Ã£o de fronteiras de contexto (bounded contexts).

Etapa 3: ExtraÃ§Ã£o de serviÃ§os mais isolados com menor acoplamento.

Etapa 4: ImplementaÃ§Ã£o de mensageria (ex: RabbitMQ) com fallback e DLQs.

Etapa 5: ImplementaÃ§Ã£o de observabilidade: logs, mÃ©tricas e tracing.

Etapa 6: Testes de regressÃ£o antes de redirecionar trÃ¡fego.

Resultado final: Arquitetura distribuÃ­da validada com ganhos de resiliÃªncia e escalabilidade.

---

## Chain of Thought (CoT)

### ğŸ¯ **EstratÃ©gias Inspiradas na Anthropic Prompt Library**

- **Persona + Objetivo + Estrutura clara:** contextualiza a funÃ§Ã£o do modelo e define o tom da resposta.
- **Chamado Ã  reflexÃ£o lÃ³gica:** "Pense passo a passo", "Justifique cada etapa".
- **Formato de saÃ­da padronizado:** etapas numeradas + conclusÃ£o objetiva.
- **AutoavaliaÃ§Ã£o embutida:** "Verifique se todos os passos estÃ£o consistentes".
- **CritÃ©rio de parada lÃ³gico:** encerrar ao atingir o raciocÃ­nio final.

### ğŸ”§ **TÃ©cnicas AvanÃ§adas de CoT com DelimitaÃ§Ãµes Estruturais (Anthropic-style)**

Modelos como Claude e GPT respondem melhor quando o prompt apresenta **delimitaÃ§Ãµes estruturais explÃ­citas**. Uma tÃ©cnica bastante utilizada pela Anthropic, segundo sua prÃ³pria Claude Prompt Library, Ã© o uso de **delimitadores XML-like** como `<thought>`, `<reasoning>`, `<answer>`, etc., para **separar raciocÃ­nio da resposta final**, melhorar a legibilidade, e tornar o prompt mais auditÃ¡vel.

### ğŸ·ï¸ **VariaÃ§Ãµes Comuns de Marcadores**

- `<context>` â€” delimita contexto inicial ou sistema.
- `<thought>` ou `<reasoning>` â€” contÃ©m o raciocÃ­nio lÃ³gico.
- `<step>` â€” pode ser usado para dividir em etapas internas.
- `<answer>` â€” resposta direta, sem explicaÃ§Ãµes.
- `<final_decision>` â€” quando hÃ¡ mÃºltiplas alternativas sendo avaliadas.

### ğŸ’¡ **MotivaÃ§Ã£o para Usar Marcadores Estruturais**

- Reduz ambiguidade entre raciocÃ­nio e resposta.
- Permite que o modelo organize suas ideias de maneira hierÃ¡rquica.
- Facilita anÃ¡lises posteriores do output por humanos ou outros sistemas.
- Ajuda o modelo a se manter dentro de um fluxo lÃ³gico, sem saltos.

---

## Chain of Thought (CoT)

### ğŸ’» **Exemplo PrÃ¡tico**

**Prompt:**

```
VocÃª Ã© um engenheiro de software especialista em arquitetura de sistemas web. Sua tarefa Ã© pensar passo a passo sobre os requisitos tÃ©cnicos para construir um backend de uma aplicaÃ§Ã£o de Todo List colaborativa com autenticaÃ§Ã£o de usuÃ¡rios, categorias personalizÃ¡veis e suporte a tarefas compartilhadas entre times.

Escreva seu raciocÃ­nio entre <thought> e o resumo tÃ©cnico final entre <answer>. Use tambÃ©m <step> para dividir o pensamento por Ã¡rea de responsabilidade.
```

**Resposta esperada:**

```xml
<thought>
  <step>
    <title>1. AutenticaÃ§Ã£o e gerenciamento de usuÃ¡rios</title>
    A aplicaÃ§Ã£o deve suportar login via e-mail e senha com autenticaÃ§Ã£o baseada em tokens JWT. UsuÃ¡rios precisam ser persistidos em um banco relacional com campos como email, senha hash, nome e data de criaÃ§Ã£o.
  </step>
  <step>
    <title>2. Modelagem de tarefas</title>
    Cada tarefa deve conter tÃ­tulo, descriÃ§Ã£o, status (pendente, concluÃ­da), data de vencimento, categoria e ID do criador. As tarefas devem poder ser atribuÃ­das a mÃºltiplos usuÃ¡rios.
  </step>
  <step>
    <title>3. Compartilhamento e permissÃµes</title>
    O sistema precisa de um controle de permissÃµes onde usuÃ¡rios podem ser organizados em times, com permissÃµes como leitura, escrita e administraÃ§Ã£o de tarefas dentro de projetos ou categorias.
  </step>
  <step>
    <title>4. Armazenamento e tecnologia</title>
    Uma stack adequada seria: backend em Go com Echo ou Fiber, banco PostgreSQL, autenticaÃ§Ã£o com JWT e middleware para RBAC (role-based access control).
  </step>
</thought>

<answer>
O backend da aplicaÃ§Ã£o Todo List deve ser construÃ­do em Go, com suporte a JWT para autenticaÃ§Ã£o, PostgreSQL para persistÃªncia e estrutura multiusuÃ¡rio com times e permissÃµes de acesso. As tarefas sÃ£o entidades colaborativas atribuÃ­das a mÃºltiplos usuÃ¡rios com categorias personalizadas e status gerenciÃ¡vel.
</answer>
```

---

## Chain of Thought (CoT)

### ğŸ“Š **Comparativo**

| Tipo de Prompt | Requer Exemplos | Gera RaciocÃ­nio | Ideal para |
|----------------|-----------------|-----------------|------------|
| Zero-Shot | Nenhum | MÃ©dia | Baixo |
| One-Shot / Few-Shot | Sim | Opcional | Imitar formato, estilo ou padrÃµes |
| Chain of Thought | Indiferente | Sim | LÃ³gica, planejamento, anÃ¡lise, debugging |

---

## ğŸ¦´ **Skeleton of Thought (SoT)**

Skeleton of Thought Prompting Ã© uma variaÃ§Ã£o de Chain of Thought onde o modelo Ã© instruÃ­do a seguir uma **estrutura lÃ³gica prÃ©-definida (um esqueleto)**, com marcadores claros de seÃ§Ãµes ou ideias centrais que devem ser preenchidas com raciocÃ­nio. Essa tÃ©cnica Ã© ideal quando o desenvolvedor deseja que a IA produza respostas **organizadas**, **completas** e **sem fugir da estrutura** desejada.

### ğŸ“š **Estudo de Base**

A tÃ©cnica foi inspirada diretamente em um estudo acadÃªmico publicado por Zhang et al. (2023) no paper **"Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding"**. Nesse trabalho, os autores mostraram que Ã© possÃ­vel separar a geraÃ§Ã£o do **esqueleto estrutural da resposta** da geraÃ§Ã£o do **conteÃºdo detalhado de cada parte**, promovendo paralelismo e coerÃªncia. Embora o foco tÃ©cnico do paper seja a melhoria de desempenho por decodificaÃ§Ã£o paralela, o mesmo princÃ­pio Ã© aplicÃ¡vel a prompting estrutural em diversos contextos como documentaÃ§Ãµes, arquitetura de software, etc.

### â° **Quando Utilizar**

- Resumos tÃ©cnicos com seÃ§Ãµes fixas
- DocumentaÃ§Ãµes, ADRs, Templates
- Quando hÃ¡ necessidade de controlar a saÃ­da e formato de uma resposta

#### ğŸ”— **Link do Paper:** https://arxiv.org/abs/2307.15337
---

## ğŸ¦´ **Skeleton of Thought (SoT)**

### ğŸ’» **Exemplo PrÃ¡tico**

**Prompt:**

```
VocÃª Ã© um engenheiro de software especializado em performance e escalabilidade. Sua tarefa Ã© propor uma soluÃ§Ã£o para implementar um rate limiter robusto que limite a taxa de requisiÃ§Ãµes por cliente. Estruture sua resposta com os seguintes tÃ³picos:

- Contexto do problema
- Requisitos funcionais e nÃ£o funcionais
- EstratÃ©gia de rate limiting
- Stack tecnolÃ³gica sugerida
- ConsideraÃ§Ãµes de concorrÃªncia e escalabilidade
- ConclusÃ£o tÃ©cnica
```

**Resposta esperada:**

**Contexto do problema:** A API serÃ¡ utilizada por centenas de clientes simultaneamente e precisa garantir que nenhum cliente ultrapasse o limite de 1000 requisiÃ§Ãµes por minuto. O sistema deve suportar atÃ© 100 mil requisiÃ§Ãµes por segundo em picos e evitar sobrecarga no backend. Ã‰ necessÃ¡rio garantir que o rate limiter funcione em ambiente distribuÃ­do.

**Requisitos funcionais e nÃ£o funcionais:**
- Cada cliente deve ter limites de requisiÃ§Ã£o individuais.
- Os limites devem ser reiniciados por janela deslizante (sliding window).
- O sistema deve ser resiliente, com baixa latÃªncia (&lt;5ms).
- Suporte a mÃºltiplas instÃ¢ncias e execuÃ§Ã£o concorrente.

**EstratÃ©gia de rate limiting:** A tÃ©cnica ideal Ã© o uso de Token Bucket com sliding window e sincronizaÃ§Ã£o via Redis. Cada cliente terÃ¡ um bucket virtual com capacidade e taxa de preenchimento ajustÃ¡vel. A cada requisiÃ§Ã£o, serÃ¡ feita uma tentativa de consumir um token. Se o token nÃ£o estiver disponÃ­vel, a requisiÃ§Ã£o serÃ¡ rejeitada com HTTP 429.

**Stack tecnolÃ³gica sugerida:**
- Linguagem: Go
- Middleware HTTP: Echo ou Fiber
- Rate limiting core: implementaÃ§Ã£o prÃ³pria ou uso do pacote golang.org/x/time/rate
- Armazenamento distribuÃ­do: Redis Cluster para controle de tokens sincronizado entre instÃ¢ncias
- Monitoramento: Prometheus + Grafana

**ConsideraÃ§Ãµes de concorrÃªncia e escalabilidade:**
- Redis deve usar LUA scripts atÃ´micos para evitar race conditions.
- Shard de clientes por chave (hash) pode distribuir melhor a carga.
- Uso de buffers internos no processo local para operaÃ§Ãµes de leitura rÃ¡pidas em cache.
- Evitar chamadas de rede por requisiÃ§Ã£o usando prefetching de tokens.

**ConclusÃ£o tÃ©cnica:** O uso de Token Bucket com Redis distribuÃ­do e implementaÃ§Ã£o otimizada em Go atende aos requisitos de latÃªncia e escalabilidade. A estrutura modular permite reuso em outros serviÃ§os. Ã‰ necessÃ¡rio fazer testes de carga com Locust e simulaÃ§Ã£o de falhas para validar a robustez da soluÃ§Ã£o em produÃ§Ã£o.

---

## Skeleton of Thought (SoT)

### ğŸ¤” **Quando Usar SoT vs CoT "Puro"**

| Quando... | Use Skeleton of Thought |
|-----------|------------------------|
| VocÃª quer controle total do formato | Sim |
| A resposta deve ser dividida por tÃ³picos | Sim |
| A tarefa exige checklist estruturado | Sim |
| A IA costuma se perder na estrutura | Sim |
| A lÃ³gica for altamente exploratÃ³ria | NÃ£o |

### ğŸ“Š **Comparativo**

| TÃ©cnica | Requer estrutura? | Raciocina passo a passo? | Ideal para... |
|---------|------------------|-------------------------|---------------|
| Zero-Shot | NÃ£o | NÃ£o | Consultas diretas, respostas factuais |
| One-Shot / Few-Shot | Parcial | Opcional | Repetir padrÃµes de exemplo com precisÃ£o |
| Chain of Thought | NÃ£o | Sim | DiagnÃ³stico, debugging, raciocÃ­nio tÃ©cnico |
| Skeleton of Thought | Sim | Opcional | Respostas organizadas, documentaÃ§Ãµes, especificaÃ§Ãµes |

---

## ğŸŒ³ **Tree of Thought (ToT)**

Tree of Thought (ToT) Ã© uma extensÃ£o da tÃ©cnica Chain of Thought (CoT) que permite que o modelo explore **mÃºltiplos caminhos de raciocÃ­nio paralelos ou alternativos** antes de tomar uma decisÃ£o final. Em vez de um raciocÃ­nio linear, o ToT incentiva o modelo a **ramificar ideias** e **avaliar alternativas**, como se estivesse construindo uma Ã¡rvore de decisÃµes.

### ğŸ“š **Estudo de Base**

A tÃ©cnica foi formalizada por Yao et al., 2023, no paper **Tree of Thoughts: Deliberate Problem Solving with Large Language Models**, mostrando ganhos significativos em tarefas complexas como jogos de lÃ³gica, planejamento e raciocÃ­nio analÃ­tico estruturado.

### â° **Quando Utilizar**

- A tarefa Ã© ambÃ­gua ou tem **mÃºltiplas soluÃ§Ãµes possÃ­veis**.
- Ã‰ necessÃ¡rio **comparar estratÃ©gias ou caminhos distintos**.
- A decisÃ£o final depende de **mÃºltiplos critÃ©rios ou trade-offs**.
- Deseja-se simular **raciocÃ­nio humano deliberado** com ponderaÃ§Ãµes.

#### ğŸ”— **Link do Paper:** https://arxiv.org/abs/2305.10601

---

## ğŸŒ³ **Tree of Thought (ToT)**

### ğŸ’» **Exemplo PrÃ¡tico**

**Prompt:**

```
VocÃª Ã© um engenheiro de software especialista em sistemas distribuÃ­dos. Um cliente quer limitar o acesso Ã  sua API que recebe atÃ© 100 mil requisiÃ§Ãµes por segundo. Gere mÃºltiplas abordagens (caminhos de raciocÃ­nio) para resolver esse problema. Para cada abordagem, exponha os prÃ³s e contras. Ao final, selecione a mais adequada com base em escalabilidade, confiabilidade e latÃªncia.
```

**Resposta esperada:**

**Caminho 1: Token Bucket com Redis**
- Permite bursts controlados.
- FÃ¡cil de implementar.
- Redis pode ser um gargalo sob carga intensa.
- Exige replicaÃ§Ã£o e scripts atÃ´micos.

**Caminho 2: Leaky Bucket com cache local**
- Boa regularizaÃ§Ã£o de trÃ¡fego.
- Alta previsibilidade de latÃªncia.
- Menos flexÃ­vel para bursts.
- Cache local pode divergir entre instÃ¢ncias.

**Caminho 3: Algoritmo Sliding Window Log**
- PrecisÃ£o de tempo real por requisiÃ§Ã£o.
- Alta granularidade.
- Alto consumo de memÃ³ria e custo computacional.
- DifÃ­cil de escalar sem otimizaÃ§Ãµes.

### AvaliaÃ§Ã£o dos caminhos
- **Escalabilidade:** Caminhos 1 e 2 sÃ£o melhores.
- **Baixa latÃªncia:** Caminho 2 se destaca.
- **Facilidade de manutenÃ§Ã£o:** Caminho 1 Ã© mais consolidado.

**Escolha final:**
Token Bucket com Redis + buffer local representa o melhor equilÃ­brio entre simplicidade, performance e tolerÃ¢ncia a falhas.

---

## Tree of Thought (ToT)

### ğŸ› ï¸ **TÃ©cnicas Auxiliares**

**ExpansÃ£o controlada de caminhos:** limite a profundidade e nÃºmero de alternativas para evitar dispersÃ£o.

```
"Apresente no mÃ¡ximo 3 caminhos distintos para resolver este problema e desenvolva atÃ© 2 nÃ­veis de subetapas para cada um."
```

**CritÃ©rios de decisÃ£o explÃ­citos:** guie o modelo com parÃ¢metros como "menor custo", "maior confiabilidade", etc.

```
"Para cada abordagem proposta, avalie com base em custo, latÃªncia e escalabilidade. Escolha a melhor com base nesses critÃ©rios."
```

**ReavaliaÃ§Ã£o iterativa:** o modelo pode revisar suas escolhas se uma nova ramificaÃ§Ã£o se mostrar superior.

```
"Depois de explorar todas as opÃ§Ãµes, reavalie as decisÃµes com base nos resultados observados em cada caminho e corrija se necessÃ¡rio."
```

---

## Tree of Thought (ToT)

### ğŸ”— **CombinaÃ§Ã£o com Outras TÃ©cnicas: ToT + CoT + SoT**

Tree of Thought Ã© altamente compatÃ­vel com outras estratÃ©gias de prompting, resultando em maior controle, completude e explicabilidade. Abaixo estÃ¡ um exemplo que combina Tree of Thought com Chain of Thought e Skeleton of Thought.

**Prompt combinado (ToT + CoT + SoT):**

```
VocÃª Ã© um engenheiro de software especialista em sistemas distribuÃ­dos. Sua tarefa Ã© projetar uma soluÃ§Ã£o de rate limiting para uma API que suporta 100 mil requisiÃ§Ãµes por segundo. Apresente 3 estratÃ©gias distintas, usando o seguinte esqueleto para cada uma:

- VisÃ£o geral da abordagem
- Etapas detalhadas do raciocÃ­nio (pense passo a passo, como um engenheiro resolveria isso em produÃ§Ã£o)
- Principais vantagens
- Principais desvantagens
- Quando usar essa abordagem

Ao final, decida qual abordagem representa o melhor equilÃ­brio para o caso proposto.
```

**Resposta esperada (resumo):**

**EstratÃ©gia 1: Token Bucket com Redis distribuÃ­do**
- **VisÃ£o geral:** Permite pequenos bursts, boa tolerÃ¢ncia Ã  falha.
- **Etapas:** Descrever uso de token bucket, scripts LUA atÃ´micos, cache local.
- **Vantagens:** Popular, flexÃ­vel, boa documentaÃ§Ã£o.
- **Desvantagens:** Requer Redis de alta disponibilidade.
- **Uso ideal:** Quando se deseja flexibilidade e controle individualizado.

**EstratÃ©gia 2: Leaky Bucket com armazenamento local**
- **VisÃ£o geral:** Regulariza fluxo de forma constante.
- **Etapas:** Descrever deque local, fallback em caso de falha.
- **Vantagens:** Mais simples, previsÃ­vel.
- **Desvantagens:** Cache local pode gerar inconsistÃªncia.
- **Uso ideal:** Quando a estabilidade do fluxo Ã© mais importante que burst handling.

**EstratÃ©gia 3: Sliding Window Log com shard por API key**
- **VisÃ£o geral:** Rastreia cada requisiÃ§Ã£o.
- **Etapas:** Uso de logs temporais por cliente.
- **Vantagens:** Alta precisÃ£o temporal.
- **Desvantagens:** Alto custo de memÃ³ria.
- **Uso ideal:** Quando a justiÃ§a de tempo real Ã© indispensÃ¡vel.

**DecisÃ£o final:** A estratÃ©gia 1 oferece o melhor equilÃ­brio entre performance, controle e robustez para a maioria dos cenÃ¡rios em produÃ§Ã£o com cargas elevadas.

---

## Tree of Thought (ToT)

### ğŸ“Š **Comparativo com Outras TÃ©cnicas**

| TÃ©cnica | Requer estrutura? | Raciocina passo a passo? | Gera mÃºltiplas alternativas? | Ideal para... |
|---------|------------------|-------------------------|------------------------------|---------------|
| Zero-Shot | NÃ£o | NÃ£o | NÃ£o | Consultas diretas, respostas factuais |
| Few-Shot | Parcial | Opcional | NÃ£o | Repetir padrÃµes de exemplo com precisÃ£o |
| Chain of Thought | NÃ£o | Sim | NÃ£o | DiagnÃ³stico, debugging, raciocÃ­nio tÃ©cnico |
| Skeleton of Thought | Sim | Opcional | NÃ£o | Respostas organizadas, documentaÃ§Ãµes, especificaÃ§Ãµes |
| Tree of Thought | Parcial | Sim | Sim | DecisÃ£o entre estratÃ©gias, brainstorming estruturado |

---

## ğŸ“Š **Resumo Comparativo: CoT, SoT, ToT**

| TÃ©cnica | SituaÃ§Ã£o ideal | Justificativa | Exemplo de prompt |
|---------|----------------|---------------|-------------------|
| Chain of Thought (CoT) | Explicar bugs | RaciocÃ­nio encadeado com lÃ³gica explicada | "Explique passo a passo por que o cÃ³digo abaixo pode gerar um panic em Go. Analise como um engenheiro faria debug em produÃ§Ã£o." |
| Skeleton of Thought (SoT) | Especificar mÃ³dulos com seÃ§Ãµes fixas | Exige consistÃªncia e organizaÃ§Ã£o por tÃ³picos | "Crie uma especificaÃ§Ã£o tÃ©cnica para um mÃ³dulo de autenticaÃ§Ã£o JWT usando os seguintes tÃ³picos: requisitos funcionais, modelo de dados, fluxos, validaÃ§Ãµes, seguranÃ§a e integraÃ§Ã£o." |
| Tree of Thought (ToT) | Comparar opÃ§Ãµes (ex: cache) | ExploraÃ§Ã£o de alternativas e decisÃ£o justificada | "Considere trÃªs formas de aplicar cache em um sistema web: in-memory, Redis e CDN. Para cada uma, descreva a estratÃ©gia, vantagens, desvantagens e cenÃ¡rio ideal de uso. Ao final, selecione a melhor com base em latÃªncia, custo e simplicidade." |
| SoT + CoT | Planejamento de arquitetura | OrganizaÃ§Ã£o por tÃ³picos com raciocÃ­nio detalhado | "Estruture a arquitetura de um sistema de Todo List com autenticaÃ§Ã£o, API REST e persistÃªncia. Responda por tÃ³picos: visÃ£o geral, autenticaÃ§Ã£o, banco de dados, fluxos principais, escalabilidade. Em cada tÃ³pico, pense passo a passo como um arquiteto de software." |
| ToT + SoT + CoT | Definir melhor stack tecnolÃ³gica | Estrutura, mÃºltiplas alternativas e raciocÃ­nio interno | "Compare as stacks Go, Node.js e Python para microserviÃ§os. Para cada uma, siga os tÃ³picos: performance, ecossistema, produtividade, complexidade de deploy e casos de uso recomendados. Dentro de cada tÃ³pico, pense passo a passo. Ao final, recomende a stack ideal para um sistema com 10 microsserviÃ§os interconectados." |
| ToT + SoT | ComparaÃ§Ã£o de bancos de dados | AnÃ¡lise comparativa organizada por critÃ©rios | "Compare os tipos de banco de dados SQL, NoSQL e NewSQL para uma aplicaÃ§Ã£o de leitura intensiva. Para cada um, responda usando os tÃ³picos: modelo de dados, escalabilidade, latÃªncia, consistÃªncia e custo operacional. Ao final, indique qual abordagem Ã© mais indicada para esse cenÃ¡rio." |

---

## ğŸ“ˆ **Resumo Comparativo: CoT, SoT, ToT**

### ğŸ¯ **Casos de Uso Abordados**

| TÃ©cnica aplicada | SituaÃ§Ã£o | Justificativa |
|-----------------|----------|---------------|
| Chain of Thought (CoT) | Explicar por que um bug ocorre | Precisa de raciocÃ­nio encadeado com lÃ³gica explicada |
| Skeleton of Thought (SoT) | Especificar um mÃ³dulo de autenticaÃ§Ã£o com seÃ§Ãµes fixas | Exige consistÃªncia e organizaÃ§Ã£o por tÃ³picos |
| Tree of Thought (ToT) | Comparar 3 formas de aplicar cache (in-memory, Redis, CDN) | Exige exploraÃ§Ã£o de alternativas e decisÃ£o final justificada |
| SoT + CoT | Planejar arquitetura de um sistema com API, banco e autenticaÃ§Ã£o | Exige estrutura e raciocÃ­nio tÃ©cnico dentro de cada seÃ§Ã£o |
| ToT + SoT + CoT | Definir melhor stack entre Go, Node.js e Python para microserviÃ§os | Requer estrutura, mÃºltiplas alternativas e raciocÃ­nio interno completo |
| ToT + SoT | Comparar bancos SQL, NoSQL e NewSQL para leitura intensiva | MÃºltiplas estratÃ©gias com anÃ¡lise tÃ©cnica estruturada, sem exigir CoT |

### ğŸ¯ **ConclusÃ£o**

Cada tÃ©cnica possui forÃ§as complementares:

- **CoT** â†’ RaciocÃ­nio lÃ³gico.
- **SoT** â†’ OrganizaÃ§Ã£o e completude.
- **ToT** â†’ ComparaÃ§Ã£o e tomada de decisÃ£o.

---

## ğŸ”„ **Self-Consistency**

### âš™ï¸ **Como Funciona a TÃ©cnica**

1. O prompt induz o modelo a pensar passo a passo (Chain of Thought).
2. A tarefa Ã© executada **diversas vezes** (tipicamente de 5 a 10).
3. As respostas geradas sÃ£o entÃ£o **coletadas e comparadas**.
4. A saÃ­da final Ã© definida por **votaÃ§Ã£o majoritÃ¡ria** ou por **mÃ©trica de consistÃªncia**.

O princÃ­pio Ã© simples: o modelo pode cometer erros em uma cadeia especÃ­fica, mas, com mÃºltiplas execuÃ§Ãµes, as respostas **mais confiÃ¡veis tendem a convergir**.

### â° **Quando Utilizar**

- HÃ¡ ambiguidade matemÃ¡tica ou estrutural.
- A tarefa Ã© suscetÃ­vel a variaÃ§Ãµes de raciocÃ­nio.
- O modelo tende a dar boas respostas Ã s vezes, mas nÃ£o sempre.
- VocÃª precisa aumentar a confiabilidade da saÃ­da com pouco custo computacional adicional.

### ğŸ’¡ **Por Que Funciona**

LLMs operam com amostragem probabilÃ­stica (ex: temperatura > 0), o que os torna suscetÃ­veis a gerar variaÃ§Ãµes, desvios ou respostas inconsistentes. Ao gerar mÃºltiplas execuÃ§Ãµes:

- Reduzimos alucinaÃ§Ãµes isoladas.
- Aumentamos a chance de obter uma resposta estatisticamente sÃ³lida.
- Priorizamos coerÃªncia entre caminhos lÃ³gicos distintos.

#### ğŸ”— **Link do Paper:** https://arxiv.org/abs/2203.11171

---

## ğŸ”„ **Self-Consistency**

### ğŸ’° **SituaÃ§Ã£o PrÃ¡tica**

VocÃª estÃ¡ desenvolvendo a estimativa de custo mensal para uma aplicaÃ§Ã£o em produÃ§Ã£o na AWS. A aplicaÃ§Ã£o utiliza:

- 10 instÃ¢ncias EC2 t3.large (regiÃ£o US East)
- 1 TB de armazenamento EBS
- 1 Load Balancer
- 100 GB de transferÃªncia de dados saindo por mÃªs

Como pequenos desvios podem ocorrer entre execuÃ§Ãµes, vocÃª decide aplicar Self-Consistency para gerar mÃºltiplas estimativas e selecionar a mais confiÃ¡vel.

**Prompt (com CoT):**

```
"Calcule o custo total mensal dessa infraestrutura. Pense passo a passo."
```

### ExecuÃ§Ãµes (resumidas):

**ExecuÃ§Ã£o 1**
- EC2: 10 x $0.0832 x 730h = $607.36
- EBS: 1024 GB x $0.10 = $102.40
- ELB: $18.00
- Data transfer: 100 GB x $0.09 = $9.00
- **Total: $736.76**

**ExecuÃ§Ã£o 2**
- EC2: $605.00 (aproximado)
- EBS: $100.00
- ELB: $18
- TransferÃªncia: $9
- **Total: $732.00**

**ExecuÃ§Ã£o 3**
- EC2: 10 Ã— 0.0832 Ã— 730 = $607.36
- EBS: 1TB Ã— 0.10 = $102.40
- Load Balancer: $18
- Data Out: $9
- **Total: $736.76**

### Resultado da Self-Consistency:

A estimativa de **$736.76** foi repetida em duas execuÃ§Ãµes com cÃ¡lculos detalhados e consistentes. Ela Ã© considerada a resposta mais confiÃ¡vel por frequÃªncia e exatidÃ£o.

**Resposta selecionada:** $736.76 â€” confirmada como mais precisa e recorrente entre as mÃºltiplas cadeias de raciocÃ­nio.

---

## Self-Consistency

### ğŸ’» **AplicaÃ§Ãµes PrÃ¡ticas em Engenharia de Software**

- Estimativas de custo e capacidade (cloud, infra, storage)
- Planejamento de sizing de ambientes
- ValidaÃ§Ã£o de resultados numÃ©ricos ou previsÃµes algorÃ­tmicas
- VerificaÃ§Ã£o de hipÃ³teses tÃ©cnicas sob mÃºltiplos critÃ©rios
- ComparaÃ§Ãµes de lÃ³gica interna em testes de arquitetura

### ğŸ’¡ **Dicas de AplicaÃ§Ã£o**

- Gere 5 a 10 respostas com **temperatura > 0.5** para estimular caminhos diversos.
- Normalize o formato da saÃ­da antes de comparar.
- Pode ser usada manualmente (humano escolhe) ou automaticamente (via votaÃ§Ã£o).

### ğŸ¯ **Exemplo Completo Usando Todas as Dicas de AplicaÃ§Ã£o**

VocÃª quer estimar o nÃºmero ideal de shards para uma base de dados multitenant com 80.000 clientes.

**Prompt:**

"Qual o nÃºmero ideal de shards para particionar uma base de dados com 80.000 clientes, considerando escalabilidade, performance e isolamento? Pense passo a passo."

**AplicaÃ§Ã£o prÃ¡tica das dicas:**

- **Temperatura variada (diversidade de raciocÃ­nio):** VocÃª gera 8 respostas com temperaturas variando entre 0.6 e 0.8 para explorar caminhos diferentes.
- **NormalizaÃ§Ã£o da saÃ­da:** Antes de comparar, remove diferenÃ§as como:
  - "~10 shards", "10", "dez" â†’ tudo Ã© convertido para "10"
  - FormataÃ§Ã£o monetÃ¡ria ou numÃ©rica (R$10k = 10000)
- **SeleÃ§Ã£o da resposta final:**
  - 5 das 8 execuÃ§Ãµes sugerem 10 shards, com raciocÃ­nios como "8000 clientes por shard", "balanceamento operacional", "flexibilidade para crescimento futuro".
  - VocÃª implementa um script simples que conta a frequÃªncia e seleciona a mais recorrente.

**Resultado final:** 10 shards â€” justificado por frequÃªncia, coerÃªncia tÃ©cnica e compatibilidade com os critÃ©rios operacionais do sistema.

---

## ğŸ¯ **Directional Stimulus / Directed Prompting**

Directed Prompting (ou Directional Stimulus Prompting) Ã© uma tÃ©cnica que guia a resposta do modelo ao utilizar verbetes, comandos ou estÃ­mulos direcionais. Diferente de prompts abertos ou vagos, essa abordagem indica como o modelo deve pensar ou responder, influenciando estilo, formato, foco ou tipo de raciocÃ­nio esperado.

### â° **Quando Utilizar**

- Quando Ã© necessÃ¡rio obter **respostas previsÃ­veis ou formatadas**.
- Quando deseja-se guiar o raciocÃ­nio por um **estilo de resposta desejado**.
- Quando a resposta precisa estar em um **formato parseÃ¡vel** (como JSON, XML, YAML).
- Quando a tarefa exige foco explÃ­cito (ex: "responda como um arquiteto", "explique em tÃ³picos").

### âœ… **BenefÃ­cios de Directed Prompting**

- Reduz ambiguidade e alucinaÃ§Ã£o.
- Padroniza a forma da resposta.
- Melhora a utilidade programÃ¡tica da saÃ­da (ex: para scripts ou interfaces).
- Permite controle educado do comportamento do modelo, sem necessidade de complexidade adicional.

#### ğŸ”— **Link do Paper:** https://arxiv.org/abs/2210.11416

---

## ğŸ¯ **Directional Stimulus**

### ğŸ“‹ **Exemplos de Comandos Direcionais Comuns**

- "Liste..."
- "Compare..."
- "Explique com exemplos..."
- "Responda em formato JSON"
- "Justifique cada item"
- "Explique como um arquiteto sÃªnior faria"
- "Divida em tÃ³picos: contexto, estratÃ©gia, riscos e conclusÃ£o"

Esses comandos **atuam como estÃ­mulos condicionais**, que alteram tanto **o formato quanto a profundidade** da resposta.

### ğŸ’» **AplicaÃ§Ãµes em Engenharia de Software**

- Gerar documentaÃ§Ã£o tÃ©cnica com estrutura especÃ­fica
- Listar vantagens/desvantagens de soluÃ§Ãµes de arquitetura
- Descrever fluxos de autenticaÃ§Ã£o, cache, filas, escalabilidade
- Padronizar output para consumo por sistemas (JSON, YAML)

---

## Directional Stimulus

### ğŸ’» **Exemplo: ComparaÃ§Ã£o de Tecnologias com Directed Prompting**

**Prompt:**

```
Compare as tecnologias Kafka, RabbitMQ e Amazon SQS para uso em sistemas distribuÃ­dos. Responda nos tÃ³picos: caracterÃ­sticas principais, throughput, confiabilidade, complexidade operacional e quando usar cada uma.
```

**Resposta esperada:**

**Kafka**
- **CaracterÃ­sticas:** distribuÃ­do, baseado em logs, alta durabilidade.
- **Throughput:** muito alto, ideal para big data e pipelines de evento.
- **Confiabilidade:** altÃ­ssima, com replicaÃ§Ã£o e retenÃ§Ã£o configurÃ¡vel.
- **Complexidade:** alta â€” exige setup de brokers, Zookeeper (ou KRaft), monitoraÃ§Ã£o ativa.
- **Quando usar:** quando o volume de dados Ã© alto e a ordem das mensagens Ã© crÃ­tica.

**RabbitMQ**
- **CaracterÃ­sticas:** orientado a fila, com suporte a mÃºltiplos protocolos (AMQP, MQTT).
- **Throughput:** mÃ©dio-alto, mais rÃ¡pido para mensagens pequenas.
- **Confiabilidade:** boa, com suporte a ACK, DLQ e persistÃªncia.
- **Complexidade:** moderada, bom tooling e fÃ¡cil operaÃ§Ã£o.
- **Quando usar:** para mensageria tradicional, RPC e integraÃ§Ã£o entre serviÃ§os.

**Amazon SQS**
- **CaracterÃ­sticas:** gerenciado, escalÃ¡vel automaticamente, simples de operar.
- **Throughput:** escalÃ¡vel sob demanda.
- **Confiabilidade:** excelente, com redundÃ¢ncia e reentrega automÃ¡tica.
- **Complexidade:** baixa â€” sem servidores para administrar.
- **Quando usar:** quando se busca simplicidade e escalabilidade sem overhead de operaÃ§Ã£o.

---

### ğŸ“Š **Directional Stimulus vs SoT**

| Aspecto | Skeleton of Thought | Directed Prompting |
|---------|--------------------|--------------------|
| Tipo de controle | Estrutura rÃ­gida com seÃ§Ãµes definidas | EstÃ­mulo leve baseado em instruÃ§Ãµes textuais |
| Modelo deve seguir tÃ³picos? | Sim | NÃ£o necessariamente |
| Liberdade de formataÃ§Ã£o | Baixa | MÃ©dia |
| Uso tÃ­pico | DocumentaÃ§Ãµes, especificaÃ§Ãµes, planejamento | ComparaÃ§Ãµes, respostas formatadas, controle de estilo |
| Exemplo de prompt | SoT: "Preencha os tÃ³picos: visÃ£o geral, arquitetura, riscos, conclusÃ£o." | "Liste as vantagens e desvantagens da arquitetura em tÃ³picos." |

---

## ğŸ”„ **ReAct (Reasoning + Action)**

ReAct (Reasoning + Acting) Ã© uma tÃ©cnica de prompting que permite que LLMs combinem **raciocÃ­nio passo a passo (Chain of Thought)** com a **execuÃ§Ã£o de aÃ§Ãµes externas** â€” como chamadas a ferramentas, busca em bancos de dados, execuÃ§Ã£o de cÃ³digo ou uso de APIs.

### ğŸ“š **Estudo de Base**

Foi formalizada no paper **"ReAct: Synergizing Reasoning and Acting in Language Models"** por Yao et al., 2022. A ideia Ã© fazer com que o modelo pense de forma deliberada e execute aÃ§Ãµes iterativas com base nesse raciocÃ­nio.

### â° **Quando Utilizar**

- Quando o modelo precisa consultar APIs, sistemas ou bancos de dados.
- Quando o raciocÃ­nio sozinho **nÃ£o Ã© suficiente** para responder.
- Quando hÃ¡ dependÃªncia de **informaÃ§Ãµes externas dinÃ¢micas**.

### âœ… **Vantagens e âš ï¸ LimitaÃ§Ãµes do ReAct Prompting**

**Vantagens:**
- Permite que o modelo **combine raciocÃ­nio com aÃ§Ã£o** em tempo real.
- Ideal para **construÃ§Ã£o de agentes interativos** (SRE, DevOps, suporte, CI/CD).
- Gera **respostas auditÃ¡veis**, pois explicita cada passo (Thought â†’ Action â†’ Observation).
- Pode ser iterado com base em **feedbacks dinÃ¢micos**, como logs ou APIs externas.
- CompatÃ­vel com ferramentas e ambientes jÃ¡ operacionais (ex: Docker, scripts, observabilidade).

**LimitaÃ§Ãµes:**
- Exige que a aÃ§Ã£o esteja simulada ou disponÃ­vel via ferramenta externa.
- Requer sistemas que integrem e interpretem a Action e Observation corretamente.
- A estrutura Thought/Action/Observation deve ser seguida Ã  risca, o que pode limitar a fluidez da linguagem.
- Aumenta a complexidade de construÃ§Ã£o e teste do prompt.

#### ğŸ”— **Link do Paper:** https://arxiv.org/abs/2210.03629

---

## ğŸ”„ **ReAct**

### ğŸ³ **Exemplo TÃ©cnico: InspeÃ§Ã£o de Containers com ReAct e Ferramenta Docker**

**Prompt**

```
VocÃª Ã© um engenheiro de plataforma. Utilize raciocÃ­nio passo a passo e a ferramenta Docker (disponÃ­vel via MCP) para inspecionar os containers que estÃ£o rodando no sistema. Seu objetivo Ã© entender o estado atual da infraestrutura. Para cada etapa, siga o padrÃ£o:

Thought: ...
Action: ...
Observation: ...
Final Answer: ...
```

**Resposta esperada**

```
Thought: Para entender o estado atual da infraestrutura, o primeiro passo Ã© listar os containers que estÃ£o em execuÃ§Ã£o.
Action: usar ferramenta Docker com comando "docker ps"
Observation: 12 containers ativos, incluindo nginx, postgres, redis, app-core, worker-1, worker-2, api-gateway, etc.

Thought: Precisamos identificar quais containers estÃ£o usando mais CPU.
Action: usar ferramenta Docker com comando "docker stats"
Observation: O container worker-2 estÃ¡ consumindo 78% de CPU, bem acima dos demais.

Thought: Isso pode indicar um ciclo de processamento contÃ­nuo. Verificar logs desse container.
Action: usar ferramenta Docker com comando "docker logs worker-2 --tail=50"
Observation: Logs mostram tarefa de processamento de mensagens em repetiÃ§Ã£o com erro de parsing.

Final Answer: O container worker-2 estÃ¡ sobrecarregado processando mensagens com erro contÃ­nuo. Deve ser investigada a origem dos dados e aplicada correÃ§Ã£o no pipeline de parsing.
```

```
Thought: Se a aplicaÃ§Ã£o estÃ¡ inacessÃ­vel, o container pode ter parado ou falhado. Vamos consultar o MCP para verificar o estado do container payments-api. Action: GET /mcp/containers?filter=name:payments-api Observation: Container payments-api estÃ¡ em status "Exited" com cÃ³digo 137 (Out of Memory).

Thought: A falha indica que o container excedeu o uso de memÃ³ria. Verificar histÃ³rico de uso de recursos. Action: GET /mcp/metrics/payments-api?range=4h Observation: Pico de uso de memÃ³ria Ã s 09:17, 09:32, 09:50 â€” ultrapassando o limite de 512MiB.

Thought: A aplicaÃ§Ã£o precisa de mais memÃ³ria. Vamos ajustar o limite e reiniciar. Action: PATCH /mcp/containers/payments-api { "memory_limit": "1GiB" } Observation: Novo limite definido com sucesso.

Thought: Agora vamos reiniciar o container. Action: POST /mcp/containers/payments-api/restart Observation: Container iniciado com sucesso. Status atual: "Running".

Final Answer: O container payments-api falhou por falta de memÃ³ria. O limite foi ajustado para 1GiB e a aplicaÃ§Ã£o voltou ao ar com sucesso.
```

```
Thought: O erro 503 geralmente indica indisponibilidade do backend. Vamos verificar se hÃ¡ ocorrÃªncias no log do serviÃ§o de checkout.
Action: GET /logs?service=checkout&since=2h
Observation: 503 errors found at 14:03, 14:05, 14:09. Spike correlates with deploy.

Thought: Pode estar relacionado ao Ãºltimo deploy. Verificar histÃ³rico de deploys.
Action: GET /deploys?service=checkout
Observation: Ãšltimo deploy Ã s 14:00.

Thought: Erros iniciaram imediatamente apÃ³s o deploy. Validar rollback.
Action: POST /rollback?service=checkout
Observation: Rollback initiated. Traffic stabilizing.

Final Answer: O erro 503 foi causado por uma falha no Ãºltimo deploy Ã s 14:00. Rollback aplicado com sucesso.
```

### ğŸ’» **AplicaÃ§Ãµes PrÃ¡ticas em Engenharia de Software**

- **DepuraÃ§Ã£o com logs ou trace APIs**

---

## ReAct

### ğŸ“Š **DiferenÃ§a entre ReAct e CoT Puro**

| ReAct | Chain of Thought (CoT) |
|-------|------------------------|
| Interage com o ambiente externo | Raciocina apenas internamente |
| Usa ferramentas | NÃ£o executa aÃ§Ãµes |
| Baseado em observaÃ§Ãµes iterativas | Baseado em raciocÃ­nio estÃ¡tico |
| Ideal para agentes ou assistentes | Ideal para explicaÃ§Ãµes e lÃ³gica |