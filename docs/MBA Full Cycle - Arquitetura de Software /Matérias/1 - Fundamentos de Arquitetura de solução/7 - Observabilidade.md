# üìà Observabilidade

## **Falando sobre Observabilidade** {#falando-sobre-observabilidade}

üéØ **Objetivo do M√≥dulo: Fundamentos de Observabilidade**

O professor inicia um novo m√≥dulo sobre **Observabilidade**. Ele esclarece que o objetivo desta etapa √© fornecer uma **ideia geral e os fundamentos** sobre o tema. Ele refor√ßa que, por se tratar de um m√≥dulo de fundamentos, a vis√£o ser√° mais superficial, com um aprofundamento ("zoom") e mais detalhes pr√°ticos sendo abordados em m√≥dulos futuros.

üó∫Ô∏è **Roteiro do M√≥dulo: O Que Ser√° Abordado**

O professor descreve os principais t√≥picos que ser√£o cobertos para construir essa base de conhecimento:

* O que √© e para que serve a observabilidade.  
* As principais diferen√ßas entre observabilidade e monitoramento.  
* As principais ferramentas de mercado para a √°rea.  
* Um destaque especial para o projeto **OpenTelemetry**, que ele descreve como "bem expressivo e com muito potencial".

## **Conceitos b√°sicos** {#conceitos-b√°sicos}

üéØ **Observabilidade e a Analogia da Caixa Preta**

O professor introduz a mentalidade da observabilidade: deve-se imaginar que quem observa o sistema (a solu√ß√£o) pode n√£o ser a mesma pessoa que o desenvolveu. A solu√ß√£o, portanto, deve ser tratada como uma **caixa preta**. N√£o √© poss√≠vel ver diretamente o que acontece internamente; em vez disso, √© preciso **inferir** ou **deduzir** o estado interno do sistema com base nos seus dados de entrada e, principalmente, de sa√≠da.

üìã **Defini√ß√£o Formal de Observabilidade**

O professor cita uma defini√ß√£o do site da New Relic, que vem da **Teoria de Controle**: "observabilidade √© definida como uma medida de qu√£o bem os estados internos de um sistema podem ser inferidos a partir do conhecimento das sa√≠das externas desse sistema". De forma mais simples, √© o **qu√£o bem voc√™ pode entender seu sistema complexo**. O trabalho consiste em verificar constantemente os dados de sa√≠da para inferir o que est√° acontecendo internamente e, com base nisso, tomar decis√µes para melhorar os resultados.

üí° **Pr√≥ximo Passo: Diferen√ßa entre Observabilidade e Monitoramento**

O professor finaliza a aula destacando um ponto de confus√£o comum: muitas pessoas pensam que observabilidade e monitoramento s√£o a mesma coisa. Ele anuncia que a diferen√ßa entre esses dois conceitos ser√° o tema do pr√≥ximo v√≠deo, para deixar o assunto bem claro.

## **Observabilidade vs Monitoramento** {#observabilidade-vs-monitoramento}

üìä **O Papel do Monitoramento (ou Monitora√ß√£o)**

O monitoramento nos mostra **que algo est√° errado**. Ele parte do princ√≠pio de que √© preciso saber **com anteced√™ncia o que se deseja monitorar** e quais s√£o os resultados esperados.

* **Exemplo Pr√°tico:** O professor usa o exemplo de monitorar a mem√≥ria RAM de uma m√°quina. N√£o basta apenas olhar a mem√≥ria; √© preciso definir um par√¢metro, como um alarme que avisa quando o uso ultrapassa 80%.  
* **Conceito Chave:** Para monitorar, voc√™ precisa saber o que procurar. A analogia usada √©: "se voc√™ n√£o sabe para onde quer ir, qualquer caminho vale".

üí° **A Fun√ß√£o da Observabilidade**

Enquanto o monitoramento aponta o erro, a observabilidade nos permite **perguntar o porqu√™** de o erro estar acontecendo. Ela n√£o mostra apenas o resultado final, mas permite **interpretar o que est√° acontecendo para entender a causa raiz** do problema. O objetivo √© entender a raz√£o do problema para poder ajust√°-lo e fazer com que o sistema volte a operar dentro dos par√¢metros monitorados.

üÜö **A Diferen√ßa Essencial: O Qu√™ vs. O Porqu√™**

O professor resume a diferen√ßa, citando uma defini√ß√£o do artigo da New Relic, da seguinte forma:

* **Monitoramento:** Mostra **o qu√™** est√° errado.  
* **Observabilidade:** Permite perguntar **o porqu√™** est√° errado.

## **Pilares vs Pipes** {#pilares-vs-pipes}

üéØ **Os Tr√™s Pilares (ou Pipes) da Observabilidade**

O professor explica que para "perguntar o porqu√™" e entender o que acontece dentro do sistema, a observabilidade se apoia em tr√™s componentes fundamentais. Ele cita uma apresenta√ß√£o da Elastic que prefere chamar esses componentes de **"pipes" (canos)** em vez de "pilares", pois eles se conectam e fluem juntos, em vez de serem estruturas independentes.

üìã **Componente 1: Logs**

* **O que s√£o:** Logs s√£o **eventos**. E um evento √© algo que aconteceu no passado (ex: "usu√°rio criado", "e-mail enviado").  
* **Conte√∫do:** Normalmente, os logs cont√™m informa√ß√µes completas, como a data, o servidor, a m√°quina e detalhes do erro, se houver. S√£o eventos que os sistemas disparam para que possamos olhar.

üìä **Componente 2: M√©tricas (Metrics)**

* **O que s√£o:** S√£o quaisquer **medidas** ou dados que podem ser agregados.  
* **Exemplos:** "Uso de 80% da mem√≥ria RAM", "m√©dia de uso de mem√≥ria de 60%", "200 pessoas no site agora", "30 compras por minuto". Tudo que pode ser medido se enquadra como m√©trica.

üë£ **Componente 3: Rastreabilidade (Tracing)**

* **O que √©:** √â a forma de **rastrear** o que est√° acontecendo dentro da "caixa preta". Permite ver o caminho completo de uma requisi√ß√£o pelas "entranhas" do software.  
* **Utilidade:** Ajuda a identificar gargalos. Exemplo: "essa requisi√ß√£o demorou porque a consulta ao banco de dados levou 5 segundos".  
* **Escopo e Contexto:** O tracing n√£o mostra apenas o caminho, mas tamb√©m o **escopo e o contexto** de uma requisi√ß√£o espec√≠fica. Isso √© crucial em um ambiente de microsservi√ßos, onde uma √∫nica a√ß√£o (como "criar uma nova conta") pode passar por v√°rios sistemas. O tracing permite acompanhar essa requisi√ß√£o √∫nica atrav√©s de todos os sistemas e identificar onde ocorreu um erro, mantendo o contexto da opera√ß√£o original.

üîó **A Ideia dos "Pipes": A Interconex√£o dos Dados**

O ponto central da apresenta√ß√£o da Elastic √© que logs, m√©tricas e tracing n√£o devem ser observados de forma separada, mas sim **em conjunto**. Eles se conectam, formando um "pipe" de informa√ß√µes.

* **Exemplo Pr√°tico:** Uma requisi√ß√£o d√° erro.  
  * O **log** diz que foi um erro ao inserir no banco.  
  * No mesmo instante, as **m√©tricas** mostram que a CPU do banco estava em 100%.  
  * E o **tracing** mostra qual foi o comando de inser√ß√£o exato que falhou.  
* **O Poder do Contexto:** Olhar para esses tr√™s dados em conjunto fornece o **contexto** completo. Um simples log isolado ou uma m√©trica de CPU alta podem n√£o significar muito, mas quando conectados, eles revelam a causa raiz do problema. √â essa informa√ß√£o integrada que permite tomar a melhor decis√£o.

## **Ferramentas populares** {#ferramentas-populares}

üó∫Ô∏è **Introdu√ß√£o e Objetivo da Aula**

O professor explica que o objetivo desta aula √© dar um "overview" sobre as principais ferramentas de observabilidade do mercado. A ideia n√£o √© aprofundar em nenhuma delas, mas sim que o aluno, ao ouvir esses nomes em uma conversa, saiba do que se trata e para que servem, permitindo que ele "sente √† mesa e converse". Ele tamb√©m d√° dois disclaimers importantes: 1\) Nenhuma empresa o pagou, n√£o √© propaganda; 2\) A ordem da lista n√£o significa ranking de popularidade ou qualidade.

üîç **Elastic Stack**

* **Natureza:** √â uma solu√ß√£o majoritariamente **open source**. Voc√™ pode instal√°-la e us√°-la sem pagar.  
* **Componentes:** O nome "Elastic Stack" vem do **Elasticsearch**, um banco de dados otimizado para busca. O **Kibana** √© o dashboard que l√™ os dados do Elasticsearch para visualiza√ß√£o. Para enviar dados da sua aplica√ß√£o para a stack, existem componentes como **Beats** e **Flee**.  
* **Modelo de Neg√≥cio:** A empresa **Elastic** oferece plugins pagos para o Kibana.  
* **Desafio Operacional:** O professor alerta que gerenciar os servidores do Elastic Stack **n√£o √© algo f√°cil ou trivial**. Por isso, muitas pessoas optam por usar o servi√ßo **Elastic Cloud**, onde a empresa gerencia a infraestrutura para voc√™ (na AWS, Azure ou Google) em troca de uma taxa.

‚òÅÔ∏è **Ferramentas SaaS Populares (Datadog, New Relic, Splunk, Dynatrace)**

* **Datadog:** Descrita como uma ferramenta "fant√°stica" com muitos servi√ßos que complementam os pilares da observabilidade.  
* **New Relic:** Uma ferramenta "extremamente tradicional" que soube se reinventar ao longo dos anos, conhecida por apresentar as informa√ß√µes de forma simples e customiz√°vel.  
* **Splunk:** Outra ferramenta "fant√°stica", muito utilizada principalmente para a gest√£o de **logs**.  
* **Dynatrace:** Tamb√©m citada como uma ferramenta "muito boa" no mercado.  
* **Estrat√©gia H√≠brida:** O professor menciona que conhece empresas que misturam ferramentas por quest√µes de custo. Por exemplo, usam o **Elastic** para logs (que s√£o caros e volumosos) e o **Datadog** para tracing, mesmo que isso cause uma perda de contexto por n√£o ter tudo integrado.

üåü *Ferramentas Cloud Native / Open Source (com asterisco)*\*

O professor destaca um grupo de ferramentas que s√£o Cloud Native e Open Source, muito populares em grandes empresas.

* **Prometheus:**  
    
  * **Foco:** **M√©tricas** (dados agregados, contadores, histogramas).  
  * **Armazenamento:** Usa um banco de dados do tipo **Time Series Database**.  
  * **Modelo de Coleta:** O modelo do Prometheus √© **pull**. Ou seja, a cada X segundos, ele acessa um endpoint na sua aplica√ß√£o para "puxar" as m√©tricas, ao contr√°rio de outras ferramentas que usam um agente para "empurrar" (`push`) os dados.  
  * **Exporters:** Para monitorar coisas que n√£o exp√µem um endpoint naturalmente (como o SO ou um banco MySQL), usam-se **exporters**. O exporter √© um plugin que l√™ os dados da fonte (ex: MySQL) e os exp√µe em um endpoint para o Prometheus poder colet√°-los.  
  * **Alarmes Inteligentes:** Seu sistema de alarme consegue entender o contexto. Exemplo: se o sistema cai (alarme 1), ele n√£o dispara um segundo alarme por "baixo n√∫mero de visitas", pois entende que a causa √© a queda do sistema.


* **Grafana:**  
    
  * **Fun√ß√£o:** Ferramenta gratuita para criar **dashboards**, normalmente utilizada em conjunto com o Prometheus para visualizar as m√©tricas.  
  * **Flexibilidade:** Tamb√©m consegue se conectar a outras fontes de dados, como o Splunk.  
  * **Dashboards da Comunidade:** Uma grande vantagem √© a exist√™ncia de dashboards prontos criados pela comunidade. Voc√™ pode pegar um c√≥digo de dashboard para Kubernetes, por exemplo, e import√°-lo, customizando apenas o que for necess√°rio.


* **Jaeger:**  
    
  * **Foco:** **Tracing**, especialmente **tracing distribu√≠do** para acompanhar uma requisi√ß√£o atrav√©s de m√∫ltiplos microsservi√ßos.  
  * **Origem:** √â um projeto open source da **CNCF (Cloud Native Computing Foundation)** e muito popular.


* **Zipkin:**  
    
  * **Foco:** Tamb√©m focado em tracing, √© considerado mais antigo e "tradicional" que o Jaeger.  
  * **Padr√£o de Tracing:** O professor destaca um ponto crucial: o formato de dados do Zipkin se tornou um padr√£o de mercado. Ele conta a **experi√™ncia pessoal** de ter uma aplica√ß√£o que enviava dados para o Zipkin e, para uma palestra na Oracle, ele conseguiu enviar os mesmos dados para a nuvem da Oracle (OCI) apenas **trocando o endpoint**, pois a OCI aceitava o mesmo padr√£o.


* **Kiali:**  
    
  * **Foco:** Rastreabilidade e visualiza√ß√£o da **comunica√ß√£o entre sistemas**.  
  * **Origem:** Nasceu para ser o sistema de rastreabilidade do **Service Mesh Istio**, rodando em cima dele para mostrar como os servi√ßos se comunicam atrav√©s dos proxies.  
  * **Evolu√ß√£o:** Hoje, o Kiali tamb√©m √© compat√≠vel com outros service meshes, como OpenShift, Linkerd e Consul.

## **OpenTelemetry** {#opentelemetry}

üåü **OpenTelemetry (OTel): O Futuro da Observabilidade**

O professor apresenta o **OpenTelemetry** como um projeto "muito promissor" e, na sua opini√£o, o "futuro da observabilidade".

* **Origem:** √â um projeto s√©rio, mantido pela **CNCF (Cloud Native Computing Foundation)**, que nasceu da jun√ß√£o de dois projetos anteriores: **OpenTracing** (padr√£o para rastreamento) e **OpenCensus**.  
* **Objetivo Principal:** A ideia √© criar um padr√£o unificado (especifica√ß√µes e protocolos) para telemetria. Quando todos os vendors (ferramentas de observabilidade) e aplica√ß√µes seguem a mesma especifica√ß√£o, fica muito mais f√°cil padronizar e, crucialmente, trocar de um provedor para outro.

üõ†Ô∏è **Componentes do Ecossistema OpenTelemetry**

* **Especifica√ß√µes e Protocolos:** Define como os dados de telemetria devem ser gerados e transmitidos.  
* **SDKs (Software Development Kits):** Kits de desenvolvimento prontos para diversas linguagens (Go, Java, Python, etc.) para que os desenvolvedores n√£o precisem implementar a especifica√ß√£o do zero. Basta importar a biblioteca e usar.  
* **Instrumenta√ß√£o Autom√°tica:** O professor explica o conceito de **instrumenta√ß√£o**. Em vez de customizar o c√≥digo da aplica√ß√£o, ferramentas e SDKs do OTel podem gerar dados de telemetria de forma autom√°tica. Exemplo: passar um par√¢metro na inicializa√ß√£o de uma aplica√ß√£o Java para que a instrumenta√ß√£o do OTel "escute" a aplica√ß√£o em tempo de execu√ß√£o e colete os dados.

üîÑ **O Fluxo de Dados com OpenTelemetry e o Coletor**

O professor explica como os dados fluem da aplica√ß√£o para o backend (a ferramenta de observabilidade como Datadog, New Relic, etc.), destacando o papel do **coletor**.

1. **Aplica√ß√£o com SDK:** A aplica√ß√£o usa o SDK do OTel para gerar os dados de telemetria.  
2. **O Coletor (Agente/Sidecar):** Em vez de enviar os dados direto para o backend, a aplica√ß√£o os envia para um **coletor**.  
   * **Padr√£o Sidecar:** O professor faz uma conex√£o importante, apontando que o coletor, quando rodando no mesmo host que a aplica√ß√£o, est√° implementando o padr√£o **Sidecar**.  
   * **Fun√ß√£o do Coletor:** Ele n√£o apenas recebe os dados, mas tamb√©m pode **tratar e transformar** essas informa√ß√µes antes de envi√°-las.  
   * **Coletor como Servi√ßo:** Al√©m do coletor-agente (sidecar), pode existir um segundo coletor rodando como um servi√ßo centralizado (em outro pod, por exemplo), que recebe dados de m√∫ltiplos agentes.

‚úÖ **As Grandes Vantagens de Usar o Padr√£o OTel**

* **Independ√™ncia de Vendor (Vendor Lock-in):** Esta √© a maior vantagem. Como os backends implementam a especifica√ß√£o OTel, voc√™ pode mudar de provedor (ex: do Elastic Stack para o AWS CloudWatch) **sem alterar o c√≥digo da sua aplica√ß√£o**. Basta mudar a configura√ß√£o do endpoint no coletor. Isso d√° um poder muito grande aos desenvolvedores.  
* **Roteamento Flex√≠vel:** O coletor pode enviar diferentes tipos de dados para diferentes backends simultaneamente. Exemplo: enviar m√©tricas e tracing para o Backend 1 (Elastic) e apenas m√©tricas para o Backend 2 (Datadog), tudo a partir de uma √∫nica fonte de dados da aplica√ß√£o.  
* **Desacoplamento:** A aplica√ß√£o n√£o precisa fazer chamadas s√≠ncronas para m√∫ltiplos backends; ela se comunica apenas com o coletor, que gerencia o envio dos dados.

‚ö†Ô∏è **Status de Implementa√ß√£o dos SDKs**

O professor d√° uma dica importante: o desenvolvimento do OpenTelemetry est√° em andamento. O status de implementa√ß√£o dos SDKs (para tracing, m√©tricas e logs) varia por linguagem. Algumas linguagens j√° t√™m suporte est√°vel para tracing e m√©tricas, enquanto logs podem estar em alfa ou ainda n√£o implementados. Ele recomenda sempre consultar o site oficial (**opentelemetry.io**) para verificar o status de cada linguagem antes de usar.